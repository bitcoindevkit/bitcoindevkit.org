[
{
	"uri": "https://bitcoindevkit.org/blog/",
	"title": "Blog",
	"tags": [],
	"description": "",
	"content": "This blog is used to publish announcements, guides and more regarding the BDK project. Anybody can contribute by sending a pull request to our GitHub repository.\n"
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Requirements The only requirement to run the bdk-cli tool is a Linux/macOS system with a fairly recent Rust toolchain installed. Since Linux distros tend to lag behind with updates, the quickest way to install the Rust compiler and Cargo is rustup.rs. You can head there and follow their instructions, after which you can test if everything went fine by running cargo version, which should print something like:\ncargo 1.45.0 (744bd1fbb 2020-06-15) If you really don\u0026rsquo;t want to pipe the output of curl into sh, you can also try using a Docker image and working inside of it, but that\u0026rsquo;s meant for more advanced users and won\u0026rsquo;t be covered in this guide.\nAt the time of writing, the project requires cargo \u0026gt;= 1.45.0, which is the latest stable as of June 2020. If you have an older version installed with rustup.rs, you can upgrade it with rustup update.\n Installing the bdk-cli tool Once Cargo is installed, you can proceed to install the interactive bdk-cli tool directly from the GitHub repository, by running:\ncargo install --git https://github.com/bitcoindevkit/bdk-cli --features=esplora This command may take a while to finish, since it will fetch and compile all the dependencies and the bdk library itself. Once it\u0026rsquo;s done, you can check if everything went fine by running bdk-cli --help which should print something like this:\nBDK CLI 0.1.0 Alekos Filini \u0026lt;alekos.filini@gmail.com\u0026gt;:Riccardo Casatta \u0026lt;riccardo@casatta.it\u0026gt; A modern, lightweight, descriptor-based wallet USAGE: bdk-cli [OPTIONS] --descriptor \u0026lt;DESCRIPTOR\u0026gt; \u0026lt;SUBCOMMAND\u0026gt; FLAGS: -h, --help Prints help information -V, --version Prints version information OPTIONS: -c, --change_descriptor \u0026lt;CHANGE_DESCRIPTOR\u0026gt; Sets the descriptor to use for internal addresses -d, --descriptor \u0026lt;DESCRIPTOR\u0026gt; Sets the descriptor to use for the external addresses --esplora_concurrency \u0026lt;ESPLORA_CONCURRENCY\u0026gt; Concurrency of requests made to the esplora server [default: 4] -e, --esplora \u0026lt;ESPLORA_URL\u0026gt; Use the esplora server if given as parameter -n, --network \u0026lt;NETWORK\u0026gt; Sets the network [default: testnet] -p, --proxy \u0026lt;PROXY_SERVER:PORT\u0026gt; Sets the SOCKS5 proxy for the Electrum client -s, --server \u0026lt;SERVER:PORT\u0026gt; Sets the Electrum server to use [default: ssl://electrum.blockstream.info:60002] -w, --wallet \u0026lt;WALLET_NAME\u0026gt; Selects the wallet to use [default: main] SUBCOMMANDS: broadcast Broadcasts a transaction to the network. Takes either a raw transaction or a PSBT to extract bump_fee Bumps the fees of an RBF transaction combine_psbt Combines multiple PSBTs into one create_tx Creates a new unsigned transaction extract_psbt Extracts a raw transaction from a PSBT finalize_psbt Finalizes a PSBT get_balance Returns the current wallet balance get_new_address Generates a new external address help Prints this message or the help of the given subcommand(s) list_transactions Lists all the incoming and outgoing transactions of the wallet list_unspent Lists the available spendable UTXOs policies Returns the available spending policies for the descriptor public_descriptor Returns the public version of the wallet\u0026#39;s descriptor(s) repl Enter REPL command loop mode sign Signs and tries to finalize a PSBT sync Syncs with the chosen blockchain server An example command to sync a testnet wallet looks like this:\nbdk-cli --descriptor \u0026quot;wpkh(tprv8ZgxMBicQKsPexGYyaFwnAsCXCjmz2FaTm6LtesyyihjbQE3gRMfXqQBXKM43DvC1UgRVv1qom1qFxNMSqVAs88qx9PhgFnfGVUdiiDf6j4/0/*)\u0026quot; --network testnet --server ssl://electrum.blockstream.info:60002 sync "
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/",
	"title": "BDK CLI",
	"tags": [],
	"description": "",
	"content": "BDK-CLI The bdk-cli repo has an example interactive shell built using the bdk library called bdk-cli that acts both as a reference implementation of a wallet and a tool to quickly experiment with descriptors and transactions.\n"
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/concept/",
	"title": "Concept",
	"tags": [],
	"description": "",
	"content": "Now, in order to better grasp some of the design choices made by BDK, it\u0026rsquo;s important to understand the main concept driving the development of this project, and the goal that it\u0026rsquo;s trying to achieve.\nBDK is aiming first of all to be a set of libraries and tools, all meant to be very reusable and adaptable. Developers working on their own wallets or other projects that are trying to integrate Bitcoin can pick the tools they need and piece them together to prototype and quickly ship a working product. This means that the bdk-cli that we\u0026rsquo;ve just installed is designed to be a very thin layer over the APIs exposed by the various components of the library, not a full, end-user-ready Bitcoin wallet.\nThis concept leads to a few design choices that are arguably very bad for the \u0026ldquo;UX\u0026rdquo; of this wallet, but that allow developers to work more directly with the underlying library. For instance:\n BDK has an internal database that\u0026rsquo;s used to store data about received transactions, spendable UTXOs, etc. This database is stored by default in your home folder, in ~/.bdk-bitcoin. The database will never contain any data that can\u0026rsquo;t be recreated purely by looking at the blockchain. Keys, descriptors, Electrum endpoints are not stored in the database. This explains why you\u0026rsquo;ll have to specify them every time in the command line. It can be seen more like a cache and can be safely deleted without risking funds. BDK doesn\u0026rsquo;t automatically \u0026ldquo;monitor\u0026rdquo; the blockchain, instead there\u0026rsquo;s a sync command that has to be called by the user. When you create a transaction and then sign it, it\u0026rsquo;s not automatically broadcast to the network. There\u0026rsquo;s a broadcast command that does this. Moreover, the command doesn\u0026rsquo;t accept a normal Bitcoin raw transaction, but instead a PSBT. That\u0026rsquo;s because internally transactions are always moved as PSBTs, and again, the broadcast command is just a very thin wrapper over the raw library call.  There are probably more of these examples, but hopefully by this point you\u0026rsquo;ll have more or less understood the gist of it. If you are not a developer, some parts of this will feel weird, inefficient, hard to understand, and that\u0026rsquo;s absolutely normal. Just try to survive through the pain and you\u0026rsquo;ll be rewarded!\n"
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/interface/",
	"title": "Interface",
	"tags": [],
	"description": "",
	"content": "Remember the bdk-cli --help command you ran before? Let\u0026rsquo;s analyze its output here to figure out the interface:\nFlags FLAGS: -h, --help Prints help information -V, --version Prints version information These are the optional flags that can be set with every command. The -h flag prints the help message, the -V flag only prints the version.\nVerbosity If you want to increase the verbosity of the output, you should use the RUST_LOG environment variable. You can set it like so to see a lot more of what\u0026rsquo;s going on behind the scenes, before running the bdk-cli command. You only have to do this once when you open a new shell, after that you can run the bdk-cli command multiple times.\nexport RUST_LOG=\u0026#34;bdk=debug\u0026#34; Options OPTIONS: -c, --change_descriptor \u0026lt;CHANGE_DESCRIPTOR\u0026gt; Sets the descriptor to use for internal addresses -d, --descriptor \u0026lt;DESCRIPTOR\u0026gt; Sets the descriptor to use for the external addresses --esplora_concurrency \u0026lt;ESPLORA_CONCURRENCY\u0026gt; Concurrency of requests made to the esplora server [default: 4] -e, --esplora \u0026lt;ESPLORA_URL\u0026gt; Use the esplora server if given as parameter -n, --network \u0026lt;NETWORK\u0026gt; Sets the network [default: testnet] -p, --proxy \u0026lt;PROXY_SERVER:PORT\u0026gt; Sets the SOCKS5 proxy for the Electrum client -s, --server \u0026lt;SERVER:PORT\u0026gt; Sets the Electrum server to use [default: ssl://electrum.blockstream.info:60002] -w, --wallet \u0026lt;WALLET_NAME\u0026gt; Selects the wallet to use [default: main] These are the global options that can be set. They are pretty much like the flags, but they also take a value. The only required one is the --descriptor or -d flag, since every wallet must have an associated descriptor.\nThe --change-descriptor flag can be used to set a different descriptor for the change addresses, sometimes called \u0026ldquo;internal\u0026rdquo; addresses in Bitcoin Core. Unfortunately there isn\u0026rsquo;t really consensus on a nice way to encode information about the change derivation inside the standard descriptor, so we are stuck with having two separate ones. Keep in mind though, that even if you don\u0026rsquo;t specify a change descriptor, you\u0026rsquo;ll still be able to create transactions - the change address will simply be generated from the standard descriptor.\nThe --network flag can be used to change the network. Right now only testnet and regtest are supported since the code is very much not production-ready yet.\nThe --server flag can be used to select the Electrum server to use. By default it\u0026rsquo;s connecting to Blockstream\u0026rsquo;s electrum servers, which seems pretty stable. If you are having connection issues, you can also try with one of the other servers listed here and see if you have more luck with those. Right now both plaintext and ssl servers are supported (prefix tcp:// or no prefix at all for tcp, prefix ssl:// for ssl).\nThe --esplora flag can be used to connect to an Esplora instance instead of using Electrum. It should be set to the API\u0026rsquo;s \u0026ldquo;base url\u0026rdquo;. For public instances of Esplora this is https://blockstream.info/api for mainnet and https://blockstream.info/testnet/api for testnet.\nThe --proxy flag can be optionally used to specify a SOCKS5 proxy to use when connecting to the Electrum server. Spawning a local Tor daemon and using it as a proxy will allow you to connect to .onion Electrum URLs. Keep in mind that only plaintext server are supported over a proxy.\nThe --wallet flag can be used to select which wallet to use, if you have more than one of them. If you get a ChecksumMismatch error when you make some changes to your descriptor, it\u0026rsquo;s because it does not match anymore the one you\u0026rsquo;ve used to initialize the cache. One solution could be to switch to a new wallet name, or delete the cache directory at ~/.bdk-bitcoin and start from scratch.\nSubcommands    Command Description     broadcast Broadcasts a transaction to the network. Takes either a raw transaction or a PSBT to extract   bump_fee Bumps the fees of an RBF transaction   combine_psbt Combines multiple PSBTs into one   create_tx Creates a new unsigned tranasaction   extract_psbt Extracts a raw transaction from a PSBT   finalize_psbt Finalizes a psbt   get_balance Returns the current wallet balance   get_new_address Generates a new external address   list_transactions Lists all the incoming and outgoing transactions of the wallet   list_unspent Lists the available spendable UTXOs   policies Returns the available spending policies for the descriptor   public_descriptor Returns the public version of the wallet\u0026rsquo;s descriptor(s)   repl Opens an interactive shell   sign Signs and tries to finalize a PSBT   sync Syncs with the chosen Electrum server    These are the main \u0026ldquo;functions\u0026rdquo; of the wallet. Most of them are pretty self explanatory, but we\u0026rsquo;ll go over them quickly anyways. You can get more details about every single command by running bdk-cli \u0026lt;subcommand\u0026gt; --help.\nbroadcast OPTIONS: --psbt \u0026lt;BASE64_PSBT\u0026gt; Sets the PSBT to extract and broadcast --tx \u0026lt;RAWTX\u0026gt; Sets the raw transaction to broadcast Broadcasts a transaction. The transaction can be a raw hex transaction or a PSBT, in which case it also has to be \u0026ldquo;finalizable\u0026rdquo; (i.e. it should contain enough partial signatures to construct a finalized valid scriptsig/witness).\nbump_fee FLAGS: -a, --send_all Allows the wallet to reduce the amount of the only output in order to increase fees. This is generally the expected behavior for transactions originally created with `send_all` OPTIONS: -f, --fee_rate \u0026lt;SATS_VBYTE\u0026gt; The new targeted fee rate in sat/vbyte -t, --txid \u0026lt;txid\u0026gt; TXID of the transaction to update --unspendable \u0026lt;TXID:VOUT\u0026gt;... Marks an utxo as unspendable, in case more inputs are needed to cover the extra fees --utxos \u0026lt;TXID:VOUT\u0026gt;... Selects which utxos *must* be added to the tx. Unconfirmed utxos cannot be used Bumps the fee of a transaction made with RBF. The transaction to bump is specified using the --txid flag and the new fee rate with --fee_rate.\nThe --send_all flag should be enabled if the original transaction was also made with --send_all.\ncombine_psbt OPTIONS: --psbt \u0026lt;BASE64_PSBT\u0026gt;... Add one PSBT to comine. This option can be repeated multiple times, one for each PSBT Combines multiple PSBTs by merging metadata and partial signatures. It can be used to merge multiple signed PSBTs into a single PSBT that contains every signature and is ready to be finalized.\ncreate_tx FLAGS: -r, --enable_rbf Enables Replace-By-Fee (BIP125) --offline_signer Make a PSBT that can be signed by offline signers and hardware wallets. Forces the addition of `non_witness_utxo` and more details to let the signer identify the change output -a, --send_all Sends all the funds (or all the selected utxos). Requires only one recipients of value 0 OPTIONS: --to \u0026lt;ADDRESS:SAT\u0026gt;... Adds a recipient to the transaction --unspendable \u0026lt;CANT_SPEND_TXID:VOUT\u0026gt;... Marks a utxo as unspendable --external_policy \u0026lt;EXT_POLICY\u0026gt; Selects which policy should be used to satisfy the external descriptor --internal_policy \u0026lt;INT_POLICY\u0026gt; Selects which policy should be used to satisfy the internal descriptor --utxos \u0026lt;MUST_SPEND_TXID:VOUT\u0026gt;... Selects which utxos *must* be spent -f, --fee_rate \u0026lt;SATS_VBYTE\u0026gt; Fee rate to use in sat/vbyte Creates a new unsigned PSBT. The flags allow to set a custom fee rate (the default is 1.0 sat/vbyte) with --fee_rate or -f, the list of UTXOs that should be considered unspendable with --unspendable (this option can be specified multiple times) and a list of UTXOs that must be spent with --utxos (again, this option can also be specified multiple times).\nThe --to option sets the receiver address of the transaction, and should contain the address and amount in Satoshi separated by a colon, like: --to 2NErbQPsooXRatRJdrXDm9wKR2fRiZDT9wL:50000. This option can also be specified multiple times to send to multiple addresses at once.\nThe --send_all flag can be used to send the value of all the spendable UTXOs to a single address, without creating a change output. If this flag is set, there must be only one --to address, and its value will be ignored (it can be set to 0).\nThe --external_policy and --internal_policy options are two advanced flags that can be used to select the spending policy that the sender intends to satisfy in this transaction. They are normally not required if there\u0026rsquo;s no ambiguity, but sometimes with a complex descriptor one or both of them have to be specified, or you\u0026rsquo;ll get a SpendingPolicyRequired error. Those flags should be set to a JSON object that maps a policy node id to the list of child indexes that the user intends to satisfy for that node. This is probably better explained with an example:\nLet\u0026rsquo;s assume our descriptor is: sh(thresh(2,pk(A),sj:and_v(v:pk(B),n:older(6)),snj:and_v(v:pk(C),after(630000)))). There are three conditions and we need to satisfy two of them to be able to spend. The conditions are:\n Sign with the key corresponding to pk(A) Sign with the key corresponding to pk(B) AND wait 6 blocks Sign with the key corresponding to pk(C) AND wait that block 630,000 is reached  So if we write down all the possible outcomes when we combine them, we get:\n Sign with pk(A) + pk(B) + wait 6 blocks Sign with pk(A) + pk(C) + wait block 630,000 Sign with pk(B) + pk(C) + wait 6 blocks + wait block 630,000  In other words:\n If we choose option #1, the final transaction will need to have the nSequence of its inputs set to a value greather than or equal to 6, but the nLockTime can stay at 0. If we choose option #2, the final transaction will need to have its nLockTime set to a value greater than or equal to 630,000, but the nSequence can be set to a final value. If we choose option #3, both the nSequence and nLockTime must be set.  The wallet can\u0026rsquo;t choose by itself which one of these combination to use, so the user has to provide this information with the --external_policy flag.\nNow, let\u0026rsquo;s draw the condition tree to understand better how the chosen policy is represented: every node has its id shown right next to its name, like qd3um656 for the root node. These ids can be seen by running the policies command. Some ids have been omitted since they are not particularly relevant, in this example we will actually only use the root id.\ngraph TD; subgraph \" \" R[\"Root - qd3um656\"] -- A[\"pk(A) - ykfuwzkl\"] R[\"Root - qd3um656\"] -- B[\"B - ms3xjley\"] B[\"B - ms3xjley\"] -- B_0[\"pk(B)\"] B[\"B - ms3xjley\"] -- B_1[\"older(6)\"] end C[\"C - d8jph6ax\"] -- C_0[\"pk(C)\"] C[\"C - d8jph6ax\"] -- C_1[\"after(630,000)\"] R[\"Root - qd3um656\"] -- C[\"C - d8jph6ax\"]  Let\u0026rsquo;s imagine that we are walking down from the root, and we want to use option #1. So we will have to select pk(A) + the whole B node. Since these nodes have an id, we can use it to refer to them and say which children we want to use. In this case we want to use children #0 and #1 of the root, so our final policy will be: --external_policy {\u0026quot;qd3um656\u0026quot;:[0,1]}.\nextract_psbt OPTIONS: --psbt \u0026lt;BASE64_PSBT\u0026gt; Sets the PSBT to extract Extracts the global transaction from a PSBT. Note that partial signatures are ignored in this step. If you want to merge the partial signatures back into the global transaction first, please use finalize_psbt first\nfinalize_psbt OPTIONS: --psbt \u0026lt;BASE64_PSBT\u0026gt; Sets the PSBT to finalize --assume_height \u0026lt;HEIGHT\u0026gt; Assume the blockchain has reached a specific height Tries to finalize a PSBT by merging all the partial signatures and other elements back into the global transaction. This command fails if there are timelocks that have not yet expired, but the check can be overridden by specifying --assume_height to make the wallet assume that a future height has already been reached.\nget_balance This subcommand has no extra flags, and simply returns the available balance in Satoshis. This command should normally be called after sync, since it only looks into the local cache to determine the list of UTXOs.\nget_new_address This subcommand has no extra flags and returns a new address. It internally increments the derivation index and saves it in the database.\nlist_transactions This subcommand has no extra flags and returns the history of transactions made or received by the wallet, with their txid, confirmation height and the amounts (in Satoshi) \u0026ldquo;sent\u0026rdquo; (meaning, the sum of the wallet\u0026rsquo;s inputs spent in the transaction) and \u0026ldquo;received\u0026rdquo; (meaning, the sum of the outputs received by the wallet). Just like get_balance it should normally be called after sync, since it only operates on the internal cache.\nlist_unspent This subcommand has no extra flags and returns the list of available UTXOs and their value in Satoshi. Just like get_balance it should normally be called after sync, since it only operates on the internal cache.\npolicies This subcommand has no extra flags and returns the spending policies encoded by the descriptor in a more human-readable format. As an example, running the policies command on the descriptor shown earlier for the in the explanation of the create_tx command, it will return this:\n This is a tree-like recursive structure, so it tends to get huge as more and more pieces are added, but it\u0026rsquo;s in fact fairly simple. Let\u0026rsquo;s analyze a simple node of the tree:\n{ \u0026#34;id\u0026#34;:\u0026#34;qd3um656\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;SIGNATURE\u0026#34;, \u0026#34;pubkey\u0026#34;:\u0026#34;...\u0026#34;, \u0026#34;satisfaction\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;NONE\u0026#34; }, \u0026#34;contribution\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;COMPLETE\u0026#34;, \u0026#34;condition\u0026#34;:{} } }   id is a unique identifier to this specific node in the tree.\n  type, as the name implies, represents the type of node. It defines what should be provided to satisfy that particular node. Generally some other data are provided to give meaning to the type itself (like the pubkey field here in the example). There are basically two families of types: some of them can only be used as leaves, while some other can only be used as intermediate nodes.\nPossible leaf nodes are:\n SIGNATURE, requires a signature made with the specified key. Has a pubkey if it\u0026rsquo;s a single key, a fingerprint if the key is an xpub, or a pubkey_hash if the full public key is not present in the descriptor. SIGNATUREKEY, requires a signature plus the raw public key. Again, it can have a pubkey, fingerprint or pubkey_hash. SHA256PREIMAGE, requires the preimage of a given hash. HASH256PREIMAGE, requires the preimage of a given hash. RIPEMD160PREIMAGE, requires the preimage of a given hash. HASH160PREIMAGE, requires the preimage of a given hash. ABSOLUTETIMELOCK, doesn\u0026rsquo;t technically require anything to be satisfied, just waiting for the timelock to expire. Has a value field with the raw value of the timelock (can be both in blocks or time-based). RELATIVETIMELOCK, again only requires waiting for the timelock to expire. Has a value like ABSOLUTETIMELOCK.  Possible non-leaf nodes are:\n THRESH, defines a threshold of policies that has to be met to satisfy the node. Has an items field, which is a list of policies to satisfy and a threshold field that defines the threshold. MULTISIG, Similar to THRESH, has a keys field, which is a list of keys represented again as either pubkey, fingerprint or pubkey_hash and a threshold field.    satisfaction is currently not implemented and will be used to provide PSBT introspection, like understanding whether or not a node is already satisfied and to which extent in a PSBT.\n  contribution represents if so and how much, the provided descriptor can contribute to the node.\nThe possible types are:\n NONE, which means that the descriptor cannot contribute. COMPLETE, which means that the descriptor by itself is enough to completely satisfy the node. It also adds a condition field which represent any potential extra condition that has to be met to consider the node complete. An example are the timelock nodes, that are always complete but they have an extra csv or timelock condition. PARTIAL, which means that the descriptor can partially satisfy the descriptor. This adds a m, n, items that respectively represent the threshold, the number of available items to satisfy and the items that the provided descriptor can satisfy. Also adds a conditions field which is an integer to list of conditions map. The key is the child index and the map are all the possibile extra conditions that have to be satisfied if that node is used in the threshold. For instance, if you have a threshold of a SIGNATURE and a RELATIVETIMELOCK, in this order, the conditions field will be 1 ‚áí csv(x), because the item at index 1 needs the extra csv condition. PARTIALCOMPLETE, which is basically a PARTIAL with the size of items \u0026gt;= m. It\u0026rsquo;s treated as a separate entity to make the code a bit more clean and easier to implement. Like PARTIAL, it also has a m, n, items fields but the conditions field is a bit different: it\u0026rsquo;s a list of integers to list of conditions map. The key represents the combination that can be used to satisfy the threshold, and the value contains all the possible conditions that also have to be satisfied. For instance, if you have a 2-of-2 threshold of a TIMELOCK and a RELATIVETIMELOCK, the conditions field will be [0, 1] ‚áí csv(x) + timelock(y), because if the combination of items 0 and 1 is picked, both of their conditions will have to be meet too.    While the structure contains all of the intermediate nodes too, the root node is the most important one because defines how the descriptor can contribute to spend outputs sent to its addresses.\nFor instance, looking at the root node of the previous example (with the internal items omitted) from a descriptor that has all the three private keys for keys A, B and C, we can clearly see that it can satisfy the descriptor (type = PARTIALCOMPLETE) and the three options are [0, 1] ‚áí csv(6) (Option #1), [0, 2] ‚áí timelock(630,000) (Option #2) or [1, 2] ‚áí csv(6) + timelock(630,000) (Option #3).\n{ \u0026#34;type\u0026#34;:\u0026#34;THRESH\u0026#34;, \u0026#34;items\u0026#34;:[], \u0026#34;threshold\u0026#34;:2, \u0026#34;satisfaction\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;NONE\u0026#34; }, \u0026#34;contribution\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;PARTIALCOMPLETE\u0026#34;, \u0026#34;n\u0026#34;:3, \u0026#34;m\u0026#34;:2, \u0026#34;items\u0026#34;:[ 0, 1, 2 ], \u0026#34;conditions\u0026#34;:{ \u0026#34;[0, 1]\u0026#34;:[ { \u0026#34;csv\u0026#34;:6 } ], \u0026#34;[0, 2]\u0026#34;:[ { \u0026#34;timelock\u0026#34;:630000 } ], \u0026#34;[1, 2]\u0026#34;:[ { \u0026#34;csv\u0026#34;:6, \u0026#34;timelock\u0026#34;:630000 } ] } } } public_descriptor This subcommand has no extra flags and returns the \u0026ldquo;public\u0026rdquo; version of the wallet\u0026rsquo;s descriptor(s). It can be used to bootstrap a watch-only instance for the wallet.\nrepl This subcommand has no extra flags and launches an interactive shell session.\nsign OPTIONS: --psbt \u0026lt;BASE64_PSBT\u0026gt; Sets the PSBT to sign --assume_height \u0026lt;HEIGHT\u0026gt; Assume the blockchain has reached a specific height. This affects the transaction finalization, if there are timelocks in the descriptor Adds to the PSBT all the signatures it can produce with the secrets embedded in the descriptor (xprv or WIF keys). Returns the signed PSBT and, if there are enough item to satisfy the script, also the extracted raw Bitcoin transaction.\nOptionally, the assume_height option can be specified to let the wallet assume the blockchain has reached a specific height. This affects the finalization of the PSBT which is done right at the end of the signing process: the wallet tries to satisfy the spending condition of each input using the partial signatures collected. In case timelocks are present the wallet needs to know whether or not they have expired. This flag is particularly useful for offline wallets.\nsync This subcommand has no extra flags. It connects to the chosen Electrum server and synchronizes the list of transactions received and available UTXOs.\n"
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/regtest/",
	"title": "Regtest",
	"tags": [],
	"description": "",
	"content": "Running the bdk-cli tool in regtest requires having a local Electrum server set-up. There are two main implementations, electrs in Rust and ElectrumX in Python. Since the Rust toolchain is already required to use BDK, this page will focus mostly on the former.\nElectrs can be installed by running:\ncargo install --git https://github.com/romanz/electrs --bin electrs Just like before, this command will probably take a while to finish.\nOnce it\u0026rsquo;s done, assuming you have a regtest bitcoind running in background, you can launch a new terminal and run the following command to actually start electrs:\nelectrs -vv --timestamp --db-dir /tmp/electrs-db --electrum-rpc-addr=\u0026#34;127.0.0.1:50001\u0026#34; --network=regtest --cookie-file=$HOME/.bitcoin/regtest/.cookie on macOS you should change the cookie-file to $HOME/Library/Application Support/Bitcoin/regtest/.cookie.\nThis will start the Electrum server on port 50001. You can then add the -n regtest -s localhost:50001 to the bdk-cli commands to switch to the local regtest.\nTroubleshooting Stuck with \u0026ldquo;wait until bitcoind is synced (i.e. initialblockdownload = false)\u0026rdquo; Just generate a few blocks with bitcoin-cli generatetoaddress 1 \u0026lt;address\u0026gt;\nBonus: Docker If you have already installed Docker on your machine, you can also use üç£ Nigiri CLI to spin-up a complete development environment in regtest that includes a bitcoin node, an electrs explorer and the esplora web-app to visualize blocks and transactions in the browser.\nInstall üç£ Nigiri\n$ curl https://getnigiri.vulpem.com | bash Start Docker daemon and run Nigiri box\n$ nigiri start This will start electrum RPC interface on port 51401, the REST interface on 3000 and the esplora UI on 5000 (You can visit with the browser and look for blocks, addresses and transactions)\nYou can then add the -n regtest -s localhost:51401 to the bdk-cli commands to switch to the local regtest.\n"
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/compiler/",
	"title": "Compiler",
	"tags": [],
	"description": "",
	"content": "Introduction If you want to play around with more complicated spending policies, you\u0026rsquo;ll start to find it harder and harder to manually create the descriptors. This is where the miniscript compiler comes in! The bdk library includes a very simple compiler that can produce a descriptor given a spending policy. The syntax used to encode the spending policy is very well described in this page, specifically in the \u0026ldquo;Policy to Miniscript compiler\u0026rdquo;. The compiler included in BDK does basically the same job, but produces descriptors for rust-miniscript that have some minor differences from the ones made by the C++ implementation used in that website.\nInstallation To install the miniscript compiler run the following command:\ncargo install --git https://github.com/bitcoindevkit/bdk --features=\u0026#34;compiler\u0026#34; --example miniscriptc Once the command is done, you should have a miniscriptc command available. You can check if that\u0026rsquo;s the case by running miniscriptc --help.\nUsage In this case the interface is very simple: it accepts two arguments called \u0026ldquo;POLICY\u0026rdquo; and \u0026ldquo;TYPE\u0026rdquo;, in this order. The first one, as the name implies, sets the spending policy to compile. The latter defines the type of address that should be used to encapsulate the produced script, like a P2SH, P2WSH, etc.\nOptionally, the --parsed_policy flag can be enabled and it will make the compiler print the JSON \u0026ldquo;human-readable\u0026rdquo; version of the spending policy, as described in the policies subcommand of the CLI.\nThe --network flag can be used to change the network encoding of the address shown.\nKeep in mind that since the compiler loads and interprets the descriptor, all the public keys specified in the policy must be valid public keys. This differs from the web tool linked above that also accepts placeholders too. As described in the previous sections of this guide, the keys can be either xpub/xprv with or without metadata and a derivation path, WIF keys or raw hex public keys.\n Example Let\u0026rsquo;s take this policy for example:\nminiscriptc --parsed_policy and(pk(cSQPHDBwXGjVzWRqAHm6zfvQhaTuj1f2bFH58h55ghbjtFwvmeXR),or(50@pk(02e96fe52ef0e22d2f131dd425ce1893073a3c6ad20e8cac36726393dfb4856a4c),older(1000)))) sh-wsh The compiler should print something like:\n[2020-04-29T10:42:05Z INFO miniscriptc] Compiling policy: and(pk(cSQPHDBwXGjVzWRqAHm6zfvQhaTuj1f2bFH58h55ghbjtFwvmeXR),or(50@pk(02e96fe52ef0e22d2f131dd425ce1893073a3c6ad20e8cac36726393dfb4856a4c),older(1000))) [2020-04-29T10:42:05Z INFO miniscriptc] ... Descriptor: sh(wsh(and_v(or_c(c:pk(02e96fe52ef0e22d2f131dd425ce1893073a3c6ad20e8cac36726393dfb4856a4c),v:older(1000)),c:pk(cSQPHDBwXGjVzWRqAHm6zfvQhaTuj1f2bFH58h55ghbjtFwvmeXR)))) [2020-04-29T10:42:05Z INFO miniscriptc] ... First address: 2MsqrJuZewY3o3ADAy1Uhi5vsBqTANjH3Cf JSON policy:\n Troubleshooting Nothing is printed This might mean that you have a RUST_LOG variable set to a value that suppresses the compiler\u0026rsquo;s log. You can try adding miniscriptc=info to your RUST_LOG value and see if that works, or open a new clean shell.\n"
},
{
	"uri": "https://bitcoindevkit.org/descriptors/",
	"title": "Descriptors",
	"tags": [],
	"description": "",
	"content": "Descriptors are a compact and semi-standard way to easily encode, or \u0026ldquo;describe\u0026rdquo;, how scripts (and subsequently, addresses) of a wallet should be generated. They can be especially helpful when working with multisigs or even more complex scripts, where the structure of the script itself is not trivial. They are a big step forward in making wallets more portable across different tools and apps, because for the first time they create a common language to describe a full bitcoin script that developers can use and integrate in their software.\nThe ecosystem around descriptors is still very much in its early stage, but they are starting to see some adoption in Bitcoin Core and other projects. BDK aims to produce the first \u0026ldquo;Native Descriptor\u0026rdquo; Bitcoin library that can be used by developers to build their own \u0026ldquo;Native Descriptor Wallets\u0026rdquo;.\nCompatibility Matrix Below are some tables to highlight the differences between Bitcoin Core\u0026rsquo;s descriptor support, rust-miniscript\u0026rsquo;s one and BDK\u0026rsquo;s.\nKey Types    Key Type BDK rust-miniscript Bitcoin Core     Hex PublicKey ‚úì ‚úì ‚úì   WIF PrivateKey ‚úì ‚úó ‚úì   Extended Keys (xpub/xprv) ‚úì ‚úó ‚úì     Script Types (top level)    Script Type BDK rust-miniscript Bitcoin Core     pk() ‚úì ‚úì ‚úì   pkh() ‚úì ‚úì ‚úì   wpkh() ‚úì ‚úì ‚úì   sh(wpkh()) ‚úì ‚úì ‚úì   sh() ‚úì ‚úì ‚úì   wsh() ‚úì ‚úì ‚úì   sh(wsh()) ‚úì ‚úì ‚úì   combo() ‚úó ‚úó ‚úì   addr() ‚úó ‚úó ‚úì   raw() ‚úó ‚úó ‚úì   Bare scripts ‚úì ‚úì ‚úó     Operators    Operator BDK rust-miniscript Bitcoin Core     pk() ‚úì ‚úì ‚úì   pk_h() ‚úì ‚úì ‚úì - as pkh()   older() ‚úì ‚úì ‚úó   after() ‚úì ‚úì ‚úó   sha256() ‚úì ‚úì ‚úó   hash256() ‚úì ‚úì ‚úó   ripemd160() ‚úì ‚úì ‚úó   hash160() ‚úì ‚úì ‚úó   andor() ‚úì ‚úì ‚úó   and_{v,b,n}() ‚úì ‚úì ‚úó   or_{b,c,d,i}() ‚úì ‚úì ‚úó   multi() ‚úì ‚úì ‚úì   thresh() ‚úì ‚úì ‚úó   sortedmulti() ‚úì ‚úì ‚úì     Modifiers    Script Type BDK rust-miniscript Bitcoin Core     a: ‚úì ‚úì ‚úó   s: ‚úì ‚úì ‚úó   c: ‚úì ‚úì ‚úó   t: ‚úì ‚úì ‚úó   d: ‚úì ‚úì ‚úó   v: ‚úì ‚úì ‚úó   j: ‚úì ‚úì ‚úó   n: ‚úì ‚úì ‚úó   l: ‚úì ‚úì ‚úó   u: ‚úì ‚úì ‚úó     For a more thorough description of these operators and modifiers see Sipa\u0026rsquo;s Miniscript Page and Bitcoin Core\u0026rsquo;s.\nExamples Some examples of valid BDK descriptors are:\n   Spending Policy Descriptor Address 0 Address 1     Static P2PKH pkh(cSQPHDBwXGjVzWRqAHm6zfvQhaTuj1f2bFH58h55ghbjtFwvmeXR) mrkwtj5xpYQjHeJe5wsweNjVeTKkvR5fCr mrkwtj5xpYQjHeJe5wsweNjVeTKkvR5fCr   Static P2PKH, watch-only pkh(02e96fe52ef0e22d2f131dd425ce1893073a3c6ad20e8cac36726393dfb4856a4c) mrkwtj5xpYQjHeJe5wsweNjVeTKkvR5fCr mrkwtj5xpYQjHeJe5wsweNjVeTKkvR5fCr   P2WSH 2-of-2 with one private key wsh(multi(2,tprv8ZgxMBicQKsPePmENhT9N9yiSfTtDoC1f39P7nNmgEyCB6Nm4Qiv1muq4CykB9jtnQg2VitBrWh8PJU8LHzoGMHTrS2VKBSgAz7Ssjf9S3P/0/*,tpubDBYDcH8P2PedrEN3HxWYJJJMZEdgnrqMsjeKpPNzwe7jmGwk5M3HRdSf5vudAXwrJPfUsfvUPFooKWmz79Lh111U51RNotagXiGNeJe3i6t/1/*)) tb1qqsat6c82fvdy73rfzye8f7nwxcz3xny7t56azl73g95mt3tmzvgs9a8vjs tb1q7sgx6gscgtau57jduend6a8l445ahpk3dt3u5zu58rx5qm27lhkqgfdjdr   P2WSH-P2SH one key + 10 days timelock sh(wsh(and_v(vc:pk_h(tprv8ZgxMBicQKsPePmENhT9N9yiSfTtDoC1f39P7nNmgEyCB6Nm4Qiv1muq4CykB9jtnQg2VitBrWh8PJU8LHzoGMHTrS2VKBSgAz7Ssjf9S3P/0/*),older(1440)))) 2Mtk2nyS98MCi2P7TkoBGLaJviBy956XxB1 2MuEStKzYhqb5HCFgHz9153tZsL5sVqV5xC     Implementation Details BDK extends the capabilities of rust-miniscript by introducing the concept of an ExtendedDescriptor: it represents a descriptor that contains one or more \u0026ldquo;derivable keys\u0026rdquo; like xpubs or xprvs and can be \u0026ldquo;derived\u0026rdquo; to a normal Descriptor by deriving every single one of its keys. It is currently called \u0026ldquo;StringDescriptor\u0026rdquo; in the code, because it\u0026rsquo;s implemented as a wrapped miniscript::Descriptor\u0026lt;String\u0026gt;.\nExtendedDescriptors are derived using a single index instead of a full derivation path: this is because normally most of the path is fixed and can be represented right after the xpub/xprv itself, and only the final index changes for each address. This is what\u0026rsquo;s normally called a DescriptorExtendedKey in codebase, and it\u0026rsquo;s the represented with a similar syntax to Bitcoin Core\u0026rsquo;s, such as:\n[d34db33f/44'/0'/0']xpub6ERApfZwUNrhL.......rBGRjaDMzQLcgJvLJuZZvRcEL/0/* "
},
{
	"uri": "https://bitcoindevkit.org/bdk-cli/playground/",
	"title": "Playground",
	"tags": [],
	"description": "",
	"content": " .error { color: orange; }   Policy Compiler     P2SH P2WSH P2SH-P2WSH    Map every alias to an existing key or generate a new one. You can also specify known keys directly in the visual editor or the policy input field.       Wallet    Descriptor   Change Descriptor (optional)          This page contains webassembly and javascript content, please enable javascript in your browser.   let compilerKeyAliasIndex = 0; function htmlToElement(html) { var template = document.createElement('template'); html = html.trim(); template.innerHTML = html; return template.content.firstChild; } function addCompilerKeyAlias(e) { if (e) { e.preventDefault(); } const newIndex = ++compilerKeyAliasIndex; const html = ` Generate WIF Key Generate Extended Key Existing Key   `; const prevAddBtn = document.getElementById('add_key_alias'); if (prevAddBtn) { prevAddBtn.remove(); } document.getElementById('compiler_aliases').appendChild(htmlToElement(html)); } function updateCompilerFormAlias(e) { const extraInput = Array.from(document.getElementsByName('extra')).filter((x) = x.attributes[\"data-index\"].value == e.attributes[\"data-index\"].value)[0]; switch (e.value) { case 'gen_wif': extraInput.style.display = 'none'; break; case 'gen_ext': extraInput.style.display = 'inherit'; extraInput.placeholder = \"Derivation Path (optional). Example: /44'/0'/0'/0/*\"; break; case 'existing': extraInput.style.display = 'inherit'; extraInput.placeholder = \"WIF, tpub or hex public key. Example: 02e96fe52ef0e22d2f131dd425ce1893073a3c6ad20e8cac36726393dfb4856a4c\"; break; } } (() = { addCompilerKeyAlias(); })();  "
},
{
	"uri": "https://bitcoindevkit.org/supporters/",
	"title": "Supporters",
	"tags": [],
	"description": "",
	"content": "The Bitcoin Dev Kit project is proudly supported by:\nBitfinex   Square Crypto    "
},
{
	"uri": "https://bitcoindevkit.org/blog/author/alekos-filini/",
	"title": "Alekos Filini",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/author/",
	"title": "Author",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/release/",
	"title": "release",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/2021/02/release-v0.4.0/",
	"title": "Release v0.4.0",
	"tags": ["rust", "release"],
	"description": "Announcing the v0.4.0 release of BDK",
	"content": "A new release of BDK is out: the v0.4.0 release brings updated dependencies, more sanity checks and an overhauled API to build transactions.\nYou can find the full v0.4.0 changelog on GitHub.\nWhat\u0026rsquo;s new in v0.4.0 Below are some highlights of the new improved APIs coming with this release:\nA new API to build transaction The star of this release is the new API designed and implemented by @llfourn that brings much more flexibility to the way we create transactions: originally the process of making a transaction involved the creation of a TxBuilder which was used to configure how the wallet should build the transaction. Things like which outputs to create, what nLockTime to use, which UTXOs to spend, and much more.\nOnce fully configured, this builder was then given to the Wallet itself in a Wallet::create_tx() or Wallet::bump_fee() call: the Wallet would try to follow the instructions given by the builder, but in case of conflicting or straight-up wrong options it would have to fail and force the user to start over.\nThe new API maintains the concept of a builder, but it changes the way it\u0026rsquo;s created so that it always contains a reference to the main Wallet instance. What this means is that most checks can now be performed right when something is added to the builder, not at the end, allowing the user to recover from errors instead of having to start over.\nThis also opens the door to even more improvements and additions, such as a way to spend foreign utxos in a transaction, or even a way to bump the fees of multiple transactions at once by batching them together, which saves a bit of space and money.\nlet send_to = wallet.get_new_address()?; let (psbt, details) = { let mut builder = wallet.build_tx(); builder .add_recipient(send_to.script_pubkey(), 50_000) .enable_rbf() .do_not_spend_change() .fee_rate(FeeRate::from_sat_per_vb(5.0)); builder.finish()? }; Upgraded dependencies This release also brings many updates to our dependencies, including:\n bitcoin to v0.26 miniscript to v5.1 electrum-client to v0.6 tokio to v1 reqwest to v0.11 cc to \u0026gt;= v1.0.64  Compact Filters example Thanks to the upgrade to bitcoin v0.26 all the issues related to new networking messages in the P2P Bitcoin network have been fixed, which means that we can finally use our (experimental) compact filters Blockchain with standard Bitcoin Core 0.21 full nodes.\nThe following example has also been added to the repository and can be run with cargo run --features=compact_filters --example compact_filters_balance.\n/// This will return wallet balance using compact filters /// Requires a synced local bitcoin node 0.21 running on testnet with blockfilterindex=1 and peerblockfilters=1 fn main() -\u0026gt; Result\u0026lt;(), CompactFiltersError\u0026gt; { env_logger::init(); info!(\u0026#34;start\u0026#34;); let num_threads = 4; let mempool = Arc::new(Mempool::default()); let peers = (0..num_threads) .map(|_| Peer::connect(\u0026#34;localhost:18333\u0026#34;, Arc::clone(\u0026amp;mempool), Network::Testnet)) .collect::\u0026lt;Result\u0026lt;_, _\u0026gt;\u0026gt;()?; let blockchain = CompactFiltersBlockchain::new(peers, \u0026#34;./wallet-filters\u0026#34;, Some(500_000))?; info!(\u0026#34;done {:?}\u0026#34;, blockchain); let descriptor = \u0026#34;wpkh(tpubD6NzVbkrYhZ4X2yy78HWrr1M9NT8dKeWfzNiQqDdMqqa9UmmGztGGz6TaLFGsLfdft5iu32gxq1T4eMNxExNNWzVCpf9Y6JZi5TnqoC9wJq/*)\u0026#34;; let database = MemoryDatabase::default(); let wallet = Arc::new(Wallet::new(descriptor, None, Network::Testnet, database, blockchain).unwrap()); wallet.sync(noop_progress(), None).unwrap(); info!(\u0026#34;balance: {}\u0026#34;, wallet.get_balance()?); Ok(()) } Contributors A huge thanks to everybody who contributed to this new release with suggestions, pull requests and bug reports.\nTODO: update numbers after release TODO: update changelog URL Since the v0.3.0 release around a month ago, we\u0026rsquo;ve had 59 new commits made by 8 different contributors for a total of 2462 additions and 1988 deletions. Here\u0026rsquo;s the full diff.\nA special thanks to the new contributor for this release:\n @luckysori - Lucas Soriano  "
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/rust/",
	"title": "rust",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/fee/",
	"title": "fee",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/2021/01/fee-estimation-for-light-clients-part-1/",
	"title": "Fee estimation for light-clients (Part 1)",
	"tags": ["fee", "machine learning"],
	"description": "Applying machine learning to the bitcoin fee estimation problem",
	"content": "This post is part 1 of 3 of a series. (Part 2, Part 3)\n Introduction: what is fee estimation? The problem  The challenges and the solution The question The data logger    Introduction: what is fee estimation? Fee estimation is the process of selecting the fee rate1 for a bitcoin transaction being created, according to two main factors:\n The current congestion of the Bitcoin network. The urgency, or lack thereof, for the transaction confirmation, i.e, its inclusion in a block.  A fee rate should be adequate to the above factors: a fee too high would be a waste of money, because the same result could have been achieved with a lower expense. On the other hand, a fee rate too low would wait for a confirmation longer than planned or, even worse, the transaction could not be confirmed at all.\nThe problem Bitcoin Core offers fee estimation through the estimatesmartfee RPC method, and there are also a lot of third-party fee estimators online, so do we need yet another estimator?\nThe model used by Bitcoin Core is not well suited for light-clients such as mobile wallets, even when running in pruned mode. Online estimators are lacking in terms of:\n Privacy: Contacting the server leaks your IP (unless you are using Tor or a VPN), and the request timing may be used to correlate the request to a transaction broadcasted to the network soon thereafter. Security: A malicious estimator could provide a high fee rate leading to a waste of money, or a low fee rate hampering the transaction confirmation.  Replace By Fee (RBF) and Child Pays For Parent (CPFP) are techniques that can somewhat minimize the fee estimation problem, because one could simply underestimate the fee rate and then raise it when necessary, however:\n RBF and CPFP may leak more information, such as patterns that may allow to detect the kind of wallet used, or which one of the transaction outputs is the change. Requires additional interaction: the client must come back \u0026ldquo;online\u0026rdquo; to perform the fee bump. Sometimes this might be impractical or risky, for instance when using an offline signer or a multisignature with geographically distributed keys.  Thus, this work is an effort to build a good fee estimator for purely peer to peer light clients such as neutrino based ones, or at least determine whether the approach we take is infeasible and open the discussion for other, better, models.\nIn the meantime, another sub-goal is pursued: attract the interest of data scientists; Indeed the initial step for this analysis consists in constructing a data set, which could also also help kickstart other studies on fee estimation or, more broadly, on the Bitcoin mempool.\nThe challenges and the solution The hardest part of doing fee estimation on a light client is the lack of information: for example, Bitcoin Core\u0026rsquo;s estimatesmartfee uses up to the last 1008 blocks and knows everything about the mempool2, such as the fee rate of every transaction it contains, but a light-client does not.\nAlso, there are other factors that may help doing fee estimation, such as the day of the week (the mempool usually empties during the weekend) or the time of the day to anticipate recurring daily events (such as the batch of bitmex withdrawals).\nThe idea is to apply Machine Learning (ML) techniques3 to discover patterns over what a light-client knows and see if they are enough to achieve consistently good estimations.\nThe question We are going to use a DNN (Deep Neural Network), a ML technique in the supervised learning branch. The \u0026ldquo;ELI5\u0026rdquo; is: give a lot of example inputs and the desired output to a black box; if there are correlations between inputs and outputs, and there are enough examples, the black box will eventually start predicting the correct output even with inputs it has never seen before.\nTo define our inputs and outputs, we need to start from the question we want to answer. For a fee estimator this is:\n\u0026ldquo;Which minimum fee rate should I use if I want this transaction to be confirmed in at most n blocks?\u0026quot;\nThis can be translated to a table with many rows like:\n   confirms_in other_information fee_rate     1 \u0026hellip; 100.34   2 \u0026hellip; 84.33   10 \u0026hellip; 44.44    where the fee_rate column is the output we want, also called the \u0026ldquo;target\u0026rdquo; or \u0026ldquo;label\u0026rdquo; in ML terminology, and the other columns are our inputs.\nCan we build this table just by looking at the Bitcoin blockchain? Unfortunately, we can\u0026rsquo;t: The main thing that\u0026rsquo;s missing is an indication of when the node first saw a transaction that has been later confirmed in a block. With that knowledge we can say that the fee rate of that transaction was the exact value required to confirm within the number of blocks it actually took to be confirmed. For instance, if we see transaction t when the blockchain is at height 1000 and then we notice that t has been included in block 1006, we can deduce that the fee rate paid by t was the exact value required to get confirmed within the next 6 blocks.\nSo to build our model, we first need to gather these data, and machine learning needs a lot of data to work well.\nThe data logger The data logger is built with the purpose of collecting all the data we need, and it\u0026rsquo;s MIT licensed open source software written in Rust.\nWe need to register the moment in time when transactions enter in the node\u0026rsquo;s mempool; to be efficient and precise we should not only call the RPC endpoints but listen to ZMQ events. Luckily, the just released bitcoin core 0.21.0 added a new ZMQ topic zmqpubsequence notifying mempool events (and block events). The logger is also listening to zmqpubrawtx and zmqpubrawblock topics, to make less RPC calls.\nWe are not only interested in the timestamp of the transaction entering the mempool, but also how many blocks it will take until the same transaction is confirmed. In the final dataset this field is called confirms_in4; if confirms_in = 1 it means the transaction is confirmed in the first block created after it has been seen for the first time.\nAnother critical piece of information logged by the data logger is the fee_rate of the transaction, since the absolute fee value paid by a bitcoin transaction is not available nor derivable given only the transaction itself, as the inputs don\u0026rsquo;t have explicit amounts.\nAll these data (apart from the time of the transaction entering in the mempool) can actually be reconstructed simply by looking at the blockchain. However, querying the bitcoin node can be fairly slow, and during the model training iterations we want to recreate the ML dataset rapidly5, for example whenever we need to modify or add a new field.\nFor these reasons, the logger is split into two parts: a process listening to the events sent by our node, which creates raw logs, and then a second process that uses these logs to create the final CSV dataset. Raw logs are self-contained: for example, they contain all the previous transaction output values for every relevant transaction. This causes some redundancy, but in this case it\u0026rsquo;s better to trade some efficiency for more performance when recreating the dataset.\nMy logger instance started collecting data on the 18th of December 2020, and as of today (25th January 2020), the raw logs are about 16GB.\nI expect (or at least hope) the raw logs, the CSV dataset, or the data logger will be useful also for other projects as well, like monitoring the propagation of transactions or other works involving raw mempool data. We will share raw logs data through torrent soon.\nIn the following Part 2 we are going to talk about the dataset.\n  The transaction fee rate is the ratio between the absolute fee expressed in satoshi, over the weight of the transaction measured in virtual bytes. The weight of the transaction is similar to the byte size, however a part of the transaction (the segwit part) is discounted, their byte size is considered less because it creates less burden for the network. \u0026#x21a9;\u0026#xfe0e;\n mempool is the set of transactions that are valid by consensus rules (for example, they are spending existing bitcoin), broadcasted in the bitcoin peer to peer network, but they are not yet part of the blockchain. \u0026#x21a9;\u0026#xfe0e;\n DISCLAIMER: I am not an expert data-scientist! \u0026#x21a9;\u0026#xfe0e;\n Conceptually similar to bitcoin core estimatesmartfee parameter called \u0026ldquo;blocks target\u0026rdquo;, however, confirms_in is the real value not the desired target. \u0026#x21a9;\u0026#xfe0e;\n 16GB of compressed raw logs are processed and a compressed CSV produced in about 5 minutes. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "https://bitcoindevkit.org/blog/2021/01/fee-estimation-for-light-clients-part-2/",
	"title": "Fee estimation for light-clients (Part 2)",
	"tags": ["fee", "machine learning"],
	"description": "Applying machine learning to the bitcoin fee estimation problem",
	"content": "This post is part 2 of 3 of a series. (Part 1, Part 3)\n The dataset  The mempool The outliers Recap    The dataset The dataset is publicly available (~500MB gzip compressed, ~2GB as plain CSV).\nThe output of the model is the fee rate, expressed in [satoshi/vbytes].\nWhat about the inputs? Generally speaking, we have two main requirements for what can be included as input for our model:\n It must be correlated to the output, even with a non-linear relation. It must be available to a light client: for instance, assuming to have knowledge and an index of the last 1000 blocks is considered too much.  To evaluate the approach we are taking, we also want to compare our model\u0026rsquo;s results with another available estimation: for this reason the dataset includes data to compute the error agains Bitcoin Core\u0026rsquo;s estimatesmartfee results, even though we are not going to use it for this model.\nThe dataset will contain only transactions that spend already confirmed inputs. If we wanted to include transactions with unconfirmed inputs as well, the fee rate would have to be computed as a whole; for example if transaction t2 spends an unconfirmed input from t1 (while t1 only spends confirmed inputs, and all its other outputs are unspent), the aggregated fee rate would have to be used. Supposing f() is extracts the absolute fee and w() the transaction weight, the aggregated fee rate would be (f(t1) + f(t2)) / (w(t1) + w(t2)). Thus, as already said previously, to keep things simple the model simply discards all the transaction that would need to perform this computation.\nFor the same reason the dataset has the parent_in_cpfp flag. When a transaction has inputs confirmed (so it\u0026rsquo;s not excluded by the previous rule) but one or more of its output have been spent by a transaction confirmed in the same block, parent_in_cpfp is 1. Transactions with parent_in_cpfp = 1 are included in the dataset but excluded by the current model, since the miner probably considered an aggregated fee rate while picking the transactions to build a block.\nThe mempool The most important input of our model is the current status of the mempool itself. However, we cannot feed the model with a list of the fee rate of every unconfirmed transaction, because this array would have a variable length. To overcome this, the transaction contained in the mempool are grouped in \u0026ldquo;buckets\u0026rdquo; which are basically subsets of the mempool where all the transactions contained in a bucket have a similar fee rate. In particular we only care about the number of transaction in every bucket, not which transactions it contains.\nThe mempool buckets array is defined by two parameters, the percentage_increment and the array_max value. Starting from the minimum fee rate value min_relay_fee=1.0, the ith element is: a_i=min_relay_fee * (1+percentage_increment)^(i+1)\nFor instance, choosing the mempool buckets array to have parameters percentage_increment = 50% and array_max = 500.0 sat/vbytes the buckets would be constructed like so:\n   bucket bucket min fee rate bucket max fee rate     a_0 1.0 1.5   a_1 1.5 2.25   a_2 2.25 3.375   a_15 437.89 inf    The array stops at a15 because a16 would have a bucket min greater than array_max.\nThe model is for light-client such as neutrino based ones. In these clients the mempool is already available (it\u0026rsquo;s needed to check for received transactions) but we can\u0026rsquo;t compute fee rates of this transactions because previous confirmed inputs are not in the mempool!\nLuckily, thanks to temporal locality 1, an important part of mempool transactions spend outputs created very recently, for example in the last 6 blocks. The blocks are available through the p2p network, and downloading the last 6 is considered a good compromise between resource consumption and accurate prediction. We need the model to be built with the same data available in the prediction phase, as a consequence the mempool data in the dataset refers only to transactions having their inputs in the last 6 blocks. However the bitcoin-csv tool inside the data logger allows to configure this parameter.\nThe outliers The dataset also contains the block percentile fee rate q_k, considering r_i to be the rate of the ith transaction in a block, q_k is the fee rate value such that for each transaction in a block r_i \u0026lt; q_k returns the k% transactions in the block that are paying lower fees.\nPercentiles are not used to feed the model but to filter some outliers tx. Removing this observations is controversial at best and considered cheating at worse. However, it should be considered that Bitcoin Core estimatesmartfee doesn\u0026rsquo;t even bother to give estimation for the next block, we think this is due to the fact that many transactions that are confirming in the next block are huge overestimation, or clearly errors like this one we found when we started logging data. These outliers are several for transactions confirming in the next block (confirms_in=1), less so for confirms_in=2, mostly disappeared for confirms_in=3 or more. It\u0026rsquo;s counterintuitive that overestimation exists for confirms_in\u0026gt;1, by definition an overestimation is a fee rate way higher than needed, so how is possible that an overestimation doesn\u0026rsquo;t enter the very next block? There are a couple of reasons why a block is discovered without containing a transaction with high fee rate:\n network latency: my node saw the transaction but the miner didn\u0026rsquo;t see that transaction yet, block building latency: the miner saw the transaction, but didn\u0026rsquo;t finish to rebuild the block template or decided it\u0026rsquo;s more efficient to finish a cycle on the older block template.  To keep the model balanced, when overestimation is filtered out, underestimation are filtered out as well. This also has the effect to remove some of the transactions possibly included because a fee is payed out-of-band. Another reason to filter transactions is that the dataset is over-represented by transactions with low confirms_in: more than 50% of transactions get confirmed in the next block, so we think it\u0026rsquo;s good to filter some of these transactions.\nThe applied filters are the following:\n   confirms_in lower higher     1 q45 q55   2 q30 q70   3 q1 q99    Not yet convinced by the removal of these outliers? The dataset contains all the observations, make your model :)\nRecap    column used in the model description     txid no Transaction hash, useful for debugging   timestamp converted The time when the transaction has been added in the mempool, in the model is used in the form day_of_week and hour   current_height no The blockchain height seen by the node in this moment   confirms_in yes This transaction confirmed at block height current_height+confirms_in   fee_rate target This transaction fee rate measured in [sat/vbytes]   fee_rate_bytes no fee rate in satoshi / bytes, used to check Bitcoin Core estimatesmartfee predictions   block_avg_fee no block average fee rate [sat/vbytes] of block current_height+confirms_in   core_econ no bitcoin estimatesmartfee result for confirms_in block target and in economic mode. Could be not available ? when a block is connected more recently than the estimation has been requested, estimation are requested every 10 secs.   core_cons no Same as above but with conservative mode   mempool_len no Sum of the mempool transactions with fee rate available (sum of every a* field)   parent_in_cpfp no It\u0026rsquo;s 1 when the transaction has outputs that are spent in the same block in which the transaction is confirmed (they are parent in a CPFP relations).   q1-q30-\u0026hellip; no Transaction confirming fast could be outliers, usually paying a lot more than required, this percentiles are used to filter those transactions,   a1-a2-\u0026hellip; yes Contains the number of transaction in the mempool with known fee rate in the ith bucket.    My biological neural network fired this, I think it's because a lot of chapters start with \"The\"  In the previous Part 1 we talked about the problem.\nIn the following Part 3 we are going to talk about the model.\n  In computer science temporal locality refers to the tendency to access recent data more often than older data. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "https://bitcoindevkit.org/blog/2021/01/fee-estimation-for-light-clients-part-3/",
	"title": "Fee estimation for light-clients (Part 3)",
	"tags": ["fee", "machine learning"],
	"description": "Applying machine learning to the bitcoin fee estimation problem",
	"content": "This post is part 3 of 3 of a series. (Part 1, Part 2)\n The model  Splitting Preprocessing Build Finally, training   The prediction phase Conclusion and future development Acknowledgements  The model The code building and training the model with tensorflow is available in google colab notebook (jupyter notebook); you can also download the file as plain python and run it locally. At least 1 hour is needed to train the full model, but it heavily depends on the hardware available.\nDo you want to choose the fee without a model? In the last 5 weeks a ~50 sat/vbyte transaction never took more than a day to confirm and a ~10 sat/vbyte never took more than a week As a reference, in the code we have a calculation of the bitcoin core estimatesmartfee MAE1 and drift2. MAE is computed as avg(abs(fee_rate - core_econ)) when core_econ is available (about 1.2M observations, sometime the value is not available when considered too old).\n   estimatesmartfee mode MAE [satoshi/vbytes] drift     economic 28.77 20.79   conservative 46.49 44.73    As seen from the table, the error is quite high, but the positive drift suggests estimatesmartfee prefers to overestimate to avoid transactions not confirming.\nAs we said in the introduction, network traffic is correlated with time and we have the timestamp of when the transaction has been first seen, however a ML model doesn\u0026rsquo;t like plain numbers too much, but it behaves better with \u0026ldquo;number that repeats\u0026rdquo;, like categories, so we are converting the timestamp in day_of_week a number from 0 to 6, and hours a number from 0 to 24.\nSplitting The dataset is splitted in training and test data with a 80/20 proportion. As the name suggest the training part is used to train the model, the test is composed of other observations to test if the model is good with observations that has never seen (proving the model can generalize, not just memorizing the answer).\nDuring the training the data is splitted again in 80/20 for training and validation respectively, validation is basically testing during training.\nDuring splitting, the dataset is converted from a pandas data frame to tensorflow dataset, decreasing training times.\nPreprocessing The preprocessing phase is part of the model however it contains transformations without parameters trained by the model. This transformations are useful because model trains better if data are in some format, and having this phase inside the model helps to avoid to prepare the data before feeding the model at prediction phase.\nOur model performs 2 kind of preprocessing:\n  Normalization: model trains faster if numerical features have mean 0 and standard deviation equal to 1, so this layer is built by computing the mean and std from the series of a feature before training, and the model is feed with (feature - mean)/std. Our model normalize confirms_in feature and all the buckets a*\n  one-hot vector: Numerical categories having a small number of different unique values like our day_of_week and hours could be trained better/faster by being converted in one hot vector. For example day_of_week=6 (Sunday) is converted in a vector ['0', '0', '0', '0', '0', '0', '1'] while day_of_week=5 (Saturday) is converted in the vector ['0', '0', '0', '0', '0', '1', '0']\n  Build all_features = tf.keras.layers.concatenate(encoded_features) x = tf.keras.layers.Dense(64, activation=\u0026#34;relu\u0026#34;)(all_features) x = tf.keras.layers.Dense(64, activation=\u0026#34;relu\u0026#34;)(x) output = tf.keras.layers.Dense(1, activation=clip)(x) model = tf.keras.Model(all_inputs, output) optimizer = tf.optimizers.Adam(learning_rate=0.01) model.compile(loss=\u0026#39;mse\u0026#39;, optimizer=optimizer, metrics=[\u0026#39;mae\u0026#39;, \u0026#39;mse\u0026#39;]) The model is fed with the encoded_features coming from the processing phase, then there are 2 layers with 64 neurons each followed by one neuron giving the fee_rate as output.\nWith this configurations the model has:\n Total params: 7,412 Trainable params: 7,361 Non-trainable params: 51  Non-trainable params comes from the normalization layer and are computed in the pre-processing phase (it contains, for example, the mean of a series). Trainable parameters are values initialized randomly and changed during the training phase. The trainable parameters are 7,361, this number comes from the following, every neuron has an associated bias and a weight for every element in the inputs, thus:\n(48 input_values_weights + 1 bias) * (64 first_layer_neurons) + (64 input_values_weights + 1 bias) * (64 second layer neurons) + (64 input values weights + 1 bias) 49*64+65*64+65 = 7361 Honestly, neural network parameters are mostly the one taken from this tensorflow example, we even tried to tune hyperparameters, however, we decided to follow this advice: \u0026ldquo;The simplest way to prevent overfitting is to start with a small model:\u0026quot;. We hope this work will attract other data scientists to this bitcoin problem, improving the model. We also think that a longer time for the data collection is needed to capture various situations.\nA significant part of a ML model are the activation functions, relu (Rectified Linear Unit) is one of the most used lately, because it\u0026rsquo;s simple and works well as we learned in this introducing neural network video. relu it\u0026rsquo;s equal to zero for negative values and equal to the input for positive values. Being non-linear allows the whole model to be non-linear.\nFor the last layer it is different: we want to enforce a minimum for the output, which is the minimum relay fee 1.03. One could not simply cut the output of the model after prediction because all the training would not consider this constraint. So we need to build a custom activation function that the model training will be able to use for the gradient descent optimization step. Luckily this is very simple using tensorflow primitives:\ndef clip(x): min = tf.constant(1.0) return tf.where(tf.less(x, min), min, x) Another important part is the optimizer, when we first read the aforementioned example the optimizer used was RMSProp however the example updated lately and we noticed the optimizer changed in favor of Adam which we read is the latest trend in data science. We changed the model to use Adam and effectively the training is faster with Adam and even slightly lower error is achieved. Another important parameter is the learning rate, which we set to 0.01 after manual trials; however there might be space for improvements such as using exponential decay, starting with an high learning rate and decreasing it through training epochs.\nThe last part of the model configuration is the loss function: the objective of the training is to find the minimum of this function. Usually for regression problem (the ones having a number as output, not a category) the most used is the Mean squared error (MSE). MSE is measured as the average of squared difference between predictions and actual observations, giving larger penalties to large difference because of the square. An interesting property is that the bigger the error the faster the changes is good at the beginning of the training, while slowing down when the model predicts better is desirable to avoid \u0026ldquo;jumping out\u0026rdquo; the local minimum.\nFinally, the model training PATIENCE = 20 MAX_EPOCHS = 200 def train(): early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE) history = model.fit(train_ds, epochs=MAX_EPOCHS, validation_data=val_ds, verbose=1, callbacks=[early_stop]) return history history = train() This steps is the core of the neural network, it takes a while, let\u0026rsquo;s analyze the output:\nEpoch 1/200 7559/7559 [==============================] - 34s 3ms/step - loss: 547.8023 - mae: 16.9547 - mse: 547.8023 - val_loss: 300.5965 - val_ma e: 11.9202 - val_mse: 300.5965 ... Epoch 158/200 7559/7559 [==============================] - 31s 3ms/step - loss: 163.2548 - mae: 8.3126 - mse: 163.2548 - val_loss: 164.8296 - val_mae: 8.3402 - val_mse: 164.8296 Training is done in epochs, under every epoch all the training data is iterated and model parameters updated to minimize the loss function.\nThe number 7559 represent the number of steps. Theoretically the whole training data should be processed at once and parameters updated accordingly, however in practice this is infeasible for example for memory resource, thus the training happens in batch. In our case we have 1,934,999 observations in the training set and our batch size is 256, thus we have 1,437,841/256=7,558.58 which by excess result in 7559 steps.\nThe ~31s is the time it takes to process the epoch on a threadripper CPU but GPU or TPU could do better.\nThe value loss is the MSE on the training data while val_loss is the MSE value on the validation data. As far as we understand the separated validation data helps to detect the machine learning enemy, overfitting. Because in case of overfitting the value loss continue to improve (almost indefinitely) while val_loss start improving with the loss but a certain point diverge, indicating the network is memorizing the training data to improve loss but in doing so losing generalizing capabilities.\nOur model doesn\u0026rsquo;t look to suffer overfitting cause loss and val_loss doesn\u0026rsquo;t diverge during training\nWhile we told the training to do 200 epochs, the training stopped at 158 because we added an early_stop call back with 20 as PATIENCE, meaning that after 20 epoch and no improvement in val_loss the training is halted, saving time and potentially avoiding overfitting.\nThe prediction phase A prediction test tool is available on github. At the moment it uses a bitcoin core node to provide network data for simplicity, but it queries it only for the mempool and the last 6 blocks, so it\u0026rsquo;s something that also a light-client could do4.\nThe following chart is probably the best visualization to evaluate the model, on the x axis there is the real fee rate while on the y axis there is the prediction, the more the points are centered on the bisection, the more the model is good. We can see the model is doing quite well, the MAE is 8 which is way lower than estimatesmartfee. However, there are big errors some times, in particular for prediction for fast confirmation (confirms_in=1 or confirms_in=2) as shown by the orange points. Creating a model only for blocks target greater than 2 instead of simply remove some observations may be an option.\nThe following chart is instead a distribution of the errors, which for good model should resemble the normal distribution centered in 0, and it loooks like the model is respecting that.\nConclusion and future development The results have shown deep neural network are a tool capable of good bitcoin transaction fee estimations; this suggests that further ML research in this area might be promising.\nThis is just a starting point, there are many future improvements such as:\n Build a separate model with full knowledge, thus for full, always-connected nodes could be interesting and improve network resource allocation with respect to current estimators. Tensorflow is a huge dependency, and since it contains all the feature to build and train a model, most of the feature are not needed in the prediction phase. In fact tensorflow lite exists which is specifically created for embedded and mobile devices; the prediction test tool and the final integration in bdk should use it. Explore other fields to improve model predictions such as:  A bucket array of the transactions in the last 6 blocks with known fee rates. This should in particular help estimations with almost empty mempool. Transaction weight Time from last block   Some fields are very important and could benefit from pre-processing expansion, for instance applying hashed feature columns to confirms_in. Bitcoin logger could be improved by a merge command to unify raw logs files, reducing redundancy and consequently disk occupation. The dataset could be created in multiple files to allow more parallelism and use less memory during training. Saving the dataset in TFRecord format instead of CSV At the moment we are training the model on a threadripper CPU, training the code on GPU or even TPU will be needed to decrease training time, especially because input data will grow. The prediction test tool should estimate only using the p2p bitcoin network, without requiring a node. This work would be propedeutic for bdk integration At the moment mempool buckets are multiple inputs a* as show in the model graph; since they are related, is it possible to merge them in one TensorArray? Sometimes the model does not learn and gets stuck. The reason is the clip function applied in the last layer is constant for a value lower than 1. In this case, the derivative is 0 and the gradient descent doesn\u0026rsquo;t know where to go. Instead of using the clip function apply penalties to the loss function for values lower than 1. There are issues regarding dead neurons (going to 0) or neurons with big weight, weight results should be monitored for this events, and also weight decay and L2 regularization should be explored. Tune hyper-parameters technique should be re-tested. Predictions should be monotonic decreasing for growing confirms_in parameter; for obvious reason it doesn\u0026rsquo;t make sense that an higher fee rate will result in a higher confirmation time. But since this is not enforced anywhere in the model, at the moment this could happen. Since nodes with bloom filter disabled doesn\u0026rsquo;t serve the mempool anymore, a model based only on last blocks should be evaluated.  Acknowledgements Thanks to Square crypto for sponsoring this work and thanks to the reviewers: Leonardo Comandini, Domenico Gabriele, Alekos Filini, Ferdinando Ametrano.\nAnd also this tweet that remembered me I had this work in my TODO list\nI don\u0026#39;t understand Machine Learning(ML), but is it horrible to use ML to predict bitcoin fees? I have heard tales of this \u0026quot;Deep Learning\u0026quot; thing where you throw a bunch of data at it and it gives you good results with high accuracy.\n\u0026mdash; sanket1729 (@sanket1729) December 9, 2020  This is the final part of the series. In the previous Part 1 we talked about the problem and in Part 2 we talked about the dataset.\n  MAE is Mean Absolute Error, which is the average of the series built by the absolute difference between the real value and the estimation. \u0026#x21a9;\u0026#xfe0e;\n drift like MAE, but without the absolute value \u0026#x21a9;\u0026#xfe0e;\n Most node won\u0026rsquo;t relay transactions with fee lower than the min relay fee, which has a default of 1.0 \u0026#x21a9;\u0026#xfe0e;\n An important issue emerged after the article came out, a bitcoin core client with bloom filter disabled (default as of 0.21) doesn\u0026rsquo;t serve the mempool via p2p. \u0026#x21a9;\u0026#xfe0e;\n   "
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/machine-learning/",
	"title": "machine learning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/author/riccardo-casatta/",
	"title": "Riccardo Casatta",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/2021/01/release-v0.3.0/",
	"title": "Release v0.3.0",
	"tags": ["rust", "release"],
	"description": "Announcing the v0.3.0 release of BDK",
	"content": "A new release of BDK is out: the v0.3.0 is a relatively small update compared to v0.2.0, but it still brings some nice APIs improvements and general bugfixes.\nYou can find the full v0.3.0 changelog on GitHub.\nWhat\u0026rsquo;s new in v0.3.0 Below are some highlights of the new improved APIs coming with this release:\nLess verbosity when using Wallet::new_offline() Now you don\u0026rsquo;t have to explicitly provide the OfflineWallet\u0026lt;_\u0026gt; type anymore, saving you one import and making it much less verbose to use.\nWhere before you were doing:\nlet wallet: OfflineWallet\u0026lt;_\u0026gt; = Wallet::new_offline(...)?; Now you can just write:\nlet wallet = Wallet::new_offline(...)?; No more error conversions in DescriptorTemplate The DescriptorTemplate trait has been updated to return a descriptor::error::Error instead of a KeyError. The descriptor!() macro has been updated as well, which means that now you can use the macro inside a DescriptorTemplate::build() implementation without having to map the error, like so:\npub struct TimeDecayingMultisig\u0026lt;K\u0026gt; { pk_a: K, pk_b: K, timelock: u32, } impl\u0026lt;K: ToDescriptorKey\u0026lt;Segwitv0\u0026gt;\u0026gt; DescriptorTemplate for TimeDecayingMultisig\u0026lt;K\u0026gt; { fn build(self) -\u0026gt; Result\u0026lt;DescriptorTemplateOut, descriptor::error::Error\u0026gt; { bdk::descriptor!(wsh(thresh(2,pk(self.pk_a),s:pk(self.pk_b),s:d:v:older(self.timelock)))) } } A new repo for the CLI The cli module (and it\u0026rsquo;s related cli-utils feature) have been removed from the main BDK repo and moved to their new home, the bdk-cli repo. The APIs exposed were mainly used internally, for the repl and the playground in our website, but in case you were using one of those keep that in mind.\nContributors A huge thanks to everybody who contributed to this new release with suggestions, pull requests and bug reports.\nSince the v0.2.0 release around a month ago, we\u0026rsquo;ve had 24 new commits made by 6 different contributors for a total of 404 additions and 1243 deletions. Here\u0026rsquo;s the full diff.\nA special thanks to the new contributor for this release:\n @tcharding - Tobin C. Harding  "
},
{
	"uri": "https://bitcoindevkit.org/blog/2020/12/release-v0.2.0/",
	"title": "Release v0.2.0",
	"tags": ["rust", "release"],
	"description": "Announcing the v0.2.0 release of BDK",
	"content": "A new release of BDK is finally out! The v0.2.0 release contains many exciting new features, bug fixes and overall improvements. This release also marks the beginning of our new regular release schedule, which will see us pushing out a new release every four weeks. We think this is a good compromise to ensure that developers using BDK have access to all the new features and fixes as soon as possible, at least while the library is still evolving very fast as it is right now. After v1.0.0 we will increase this time to a more relaxed 6 weeks.\nYou can find the full v0.2.0 changelog on GitHub.\nWhat\u0026rsquo;s new in v0.2.0 Considering the sheer amount of new things being added we don\u0026rsquo;t have room here to explain every new feature in detail, but below is a quick overview of some you could find useful in your projects.\nA new name The 0.1.0-beta.1 release was tagged right before the project was renamed bdk: at that time the library was still called \u0026ldquo;Magical Bitcoin Library\u0026rdquo;, or magical for short. With this release we have now renamed it to bdk. If you were using the library before, it should only be a matter of renaming the imports to match the new name. Alternatively you can also rename bdk to magical in your Cargo.toml, but you\u0026rsquo;ll still have to do some changes here and there because the APIs have been changed in a few places.\nThis release being particularly large contains a few different API-breaking changes: going forward we expect to make the interface more and more stable, which in turn will make applying updates easier.\nBranch and Bound coin selection We now support the state-of-the-art coin selection algorithm called \u0026ldquo;branch and bound\u0026rdquo;, with an implementation derived straight from Bitcoin Core. This algorithm is now enabled by default, but it can be replaced with a different one (either the old default, LargestFirstCoinSelection or a custom CoinSelectionAlgorithm) by using the TxBuilder::coin_selection() option.\nBranch and bound works by trying to find a set of inputs that perfectly matches the amount being sent by a transaction, to avoid making an extra change output which takes up more space in the transaction, requires more fees, and in general lowers the privacy of a user if the change is later spent together with other outputs.\nKey generation If you need to generate a new bip32::ExtendedPrivKey, or perhaps a new BIP39 mnemonic, you can use the unified GeneratableKey trait to do so: paired with GeneratableDefaultOptions they provide many different ways to generate keys, with or without a custom source of entropy, and with or without customized options.\nuse bdk::bitcoin::PrivateKey; use bdk::keys::{GeneratableKey, GeneratableDefaultOptions, PrivateKeyGenerateOptions}; let default_options_key = PrivateKey::generate_default()?; let custom_options_key = PrivateKey::generate(PrivateKeyGenerateOptions { compressed: false })?; Generic key types With this update there\u0026rsquo;s now a generalized trait for keys that can be used in descriptors, which is called ToDescriptorKey. This trait is already implemented for the native rust-bitcoin key types, like PrivateKey, PublicKey, bip32::ExtendedPrivKey and bip32::ExtendedPubKey. It\u0026rsquo;s also implemented for BIP39 mnemonic and seeds, when the the opt-in keys-bip39 feature is enabled. As always, being this a public trait, you can also implement it for custom types to better suit your needs.\nimpl\u0026lt;Ctx: ScriptContext\u0026gt; ToDescriptorKey\u0026lt;Ctx\u0026gt; for MyKeyType { fn to_descriptor_key(self) -\u0026gt; Result\u0026lt;DescriptorKey\u0026lt;Ctx\u0026gt;, KeyError\u0026gt; { // Custom conversion to `bitcoin::PrivateKey`  let privkey: bitcoin::PrivateKey = ... ; privkey.to_descriptor_key() } } If your custom key type is simply a different representation of an xprv or xpub, you can also consider implementing the DerivableKey trait instead: for a type K that implements DerivableKey, the ToDescriptorKey trait is automatically implemented for the (K, bip32::DerivationPath) and (K, bip32::KeySource, bip32::DerivationPath) tuples.\nimpl\u0026lt;Ctx: ScriptContext\u0026gt; DerivableKey\u0026lt;Ctx\u0026gt; for MyKeyType { fn add_metadata( self, origin: Option\u0026lt;KeySource\u0026gt;, derivation_path: DerivationPath ) -\u0026gt; Result\u0026lt;DescriptorKey\u0026lt;Ctx\u0026gt;, KeyError\u0026gt; { // Custom conversion to `bip32::ExtendedPrivKey`  let xprv: bip32::ExtendedPrivKey = ... ; xprv.add_metadata(origin, derivation_path) } } Descriptor templates Instead of having to serialize keys to strings using format!() just to place them somewhere inside a descriptor, you can now use descriptor templates to build a descriptor starting from a key and some other options in a couple of lines of code. You can use one of the provided templates or make a custom one by implementing the DescriptorTemplate trait on a struct or enum.\nlet key = bip32::ExtendedPrivKey::from_str(\u0026#34;...\u0026#34;)?; let wallet: OfflineWallet\u0026lt;_\u0026gt; = Wallet::new_offline( BIP84(key.clone(), KeychainKind::External), Some(BIP84(key, KeychainKind::Internal)), Network::Testnet, MemoryDatabase::default(), )?; Easier creation of Blockchain and Database We\u0026rsquo;ve added a new way to create a Blockchain instance from a configuration, with the ConfigurableBlockchain trait. All the Blockchain types provided by the library implement this trait, which allows you to easily build an instance of them starting from a configuration struct: moreover, the configuration structures implement Serialize and Deserialize, so that they can be easily stored/loaded using serde.\nWe\u0026rsquo;ve also added a new Blockchain type called AnyBlockchain, which is essentially an enum that wraps all the Blockchain types exposed by the library. This allows you to build a Wallet that always has the same Rust type, but that can internally use different Blockchain backends chosen at runtime.\nuse bdk::blockchain::{AnyBlockchain, AnyBlockchainConfig, ConfigurableBlockchain, ElectrumBlockchainConfig}; let config = r#\u0026#34;{\u0026#34;Electrum\u0026#34;:{\u0026#34;url\u0026#34;:\u0026#34;ssl://electrum.blockstream.info:50002\u0026#34;,\u0026#34;socks5\u0026#34;:null,\u0026#34;retry\u0026#34;:3,\u0026#34;timeout\u0026#34;:5}}\u0026#34;#; let config = serde_json::from_str(config)?; let blockchain = AnyBlockchain::from_config(\u0026amp;config)?; The same is true for Database types, thanks to the ConfigurableDatabase trait and the AnyDatabase enum. While we think most people generally prefer to choose a single database type and then stick to it, it\u0026rsquo;s still good to offer the choice to switch them at runtime, should somebody need that.\ndescriptor!() macro If you start writing complex descriptor templates, you\u0026rsquo;ll soon find yourself with the need of building large descriptor syntax trees: you can very easily do that with the descriptor!() macro, with the added bonus that some additional checks on the syntax of your descriptor will be performed at compile-time, rather than at runtime by. You can use any type that implements ToDescriptorKey (even strings!) as keys in pk(), multi() and sortedmulti() fragments, and you can even mix them in the same descriptor.\nThe syntax supported by the macro is almost exactly the same as the standard descriptor syntax we all know, with the only difference that modifiers should be specified individually rather than grouped in a series of characters (see the example below).\npub struct TimeDecayingMultisig\u0026lt;K\u0026gt; { pk_a: K, pk_b: K, timelock: u32, } impl\u0026lt;K: ToDescriptorKey\u0026lt;Segwitv0\u0026gt;\u0026gt; DescriptorTemplate for TimeDecayingMultisig\u0026lt;K\u0026gt; { fn build(self) -\u0026gt; Result\u0026lt;DescriptorTemplateOut, KeyError\u0026gt; { Ok(bdk::descriptor!(wsh(thresh(2,pk(self.pk_a),s:pk(self.pk_b),s:d:v:older(self.timelock)))) .map_err(|e| KeyError::Message(e.to_string()))?) } } Support for sortedmulti() Thanks to the addition of sortedmulti() in rust-miniscript, we can now also support them in BDK, which means we are getting more and more compatible with other descriptor-based wallets out there like Bitcoin Core.\nContributors A huge thanks to everybody who contributed to this new release with suggestions, pull requests and bug reports.\nSince the 0.1.0-beta.1 release over three months ago, we\u0026rsquo;ve had 213 new commits made by 10 different contributors for a total of 9990 additions and 2993 deletions. Here\u0026rsquo;s the full diff.\nA special thanks to the 7 new contributors:\n @eupn @justinmoon - Justin Moon @Xekyo - Mark Erhardt @RCasatta - Riccardo Casatta @ulrichard - Richard Ulrich @notmandatory - Steve Myers @willcl-ark - Will Clark  "
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/getting-started/",
	"title": "getting started",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/2020/12/hello-world/",
	"title": "Hello World!",
	"tags": ["getting started", "rust"],
	"description": "Getting started using the BDK library in a very simple Rust project",
	"content": "Introduction This article should serve as a \u0026ldquo;getting started\u0026rdquo; guide for developers who are considering integrating BDK in their projects: it tries to introduce the reader to the basic concepts behind the library and some of its modules and components that can be used to build a very simple functioning Bitcoin wallet. All the information written in this article are valid for the current master git branch, and should remain valid for the upcoming v0.2.0 release which is planned to be tagged pretty soon.\nDesign Goals The main goal of the library is to be a solid foundation for Bitcoin wallets of any kind, on any platform: in practice, this means that the library should be:\n Very well-reviewed and tested Lightweight, so that it can be used easily on mobile devices as well Extendable, so that it can be adapted to perfectly suit different use-cases Generalized, meaning that it supports different types of Bitcoin scripts and wallets through the use of descriptors Reasonably easy to use, exposing a \u0026ldquo;high level\u0026rdquo; interface to the user and hiding all the complexity inside  These goals have a direct impact on the design of the internal components of the library, and as a consequence on the APIs that are exposed to the final user, which might in some cases feel counter-intuitive at first. Throughout the article, I will try to focus on those points and try to explain them as best as I can.\nThe Wallet Structure The Wallet structure is in many ways the heart of the library: it represents an instance of a wallet and exposes some APIs to perform all the typical operations one might want to do with a Bitcoin wallet, such as generating a new address, listing the transactions received, creating a transaction, etc.\nA Wallet instance can be constructed given at least one descriptor which would be used to derive both External and Internal addresses, or two if one prefers to keep them separated. External addresses are the ones returned by an explicit Wallet::get_new_address() call, while Internal addresses are generated internally to receive the change whenever a new transaction is created.\nA Wallet also needs at least one other component to function properly, its Database: it will be used as a cache to store the list of transactions synchronized with the blockchain, the UTXOs, the addresses generated, and a few other things. It\u0026rsquo;s important to note that the Database will never store any secret. Securely storing keys is explicitly left to the user of the library to implement, mainly because there isn\u0026rsquo;t really one good way to do it, that would work reliably on every platform. On mobile devices, for instance, the OS' keychain could be used, to allow unlocking the secrets with the use of biometric data (FaceID or fingerprint), while on desktop platform there isn\u0026rsquo;t generally a similar framework available and the user would have to implement something that meets their needs. It\u0026rsquo;s not excluded that in the future we could provide a \u0026ldquo;reference implementation\u0026rdquo; of secure multi-platform storage for keys, but that would very likely be released as a separate module outside of the Wallet structure, or potentially even as a separate library that could be reused for other applications as well.\nGoing back to our Wallet: given a descriptor and a Database we can build an \u0026ldquo;air-gapped\u0026rdquo;, or \u0026ldquo;Offline\u0026rdquo; wallet: basically, a wallet that physically can\u0026rsquo;t to connect to the Bitcoin network. It will still be able to generate addresses and sign PSBTs, but with a greatly reduced attack surface because a sizable part of the code that handles the logic to synchronize with the network would be entirely omitted in the final executable binary.\nThis is how an OfflineWallet can be created. Notice that we are using MemoryDatabase as our Database. We\u0026rsquo;ll get to that in a second.\nuse bdk::{Wallet, OfflineWallet}; use bdk::database::MemoryDatabase; use bdk::bitcoin::Network; fn main() -\u0026gt; Result\u0026lt;(), Box\u0026lt;dyn std::error::Error\u0026gt;\u0026gt; { let external_descriptor = \u0026#34;wpkh(tprv8ZgxMBicQKsPdy6LMhUtFHAgpocR8GC6QmwMSFpZs7h6Eziw3SpThFfczTDh5rW2krkqffa11UpX3XkeTTB2FvzZKWXqPY54Y6Rq4AQ5R8L/84\u0026#39;/0\u0026#39;/0\u0026#39;/0/*)\u0026#34;; let internal_descriptor = \u0026#34;wpkh(tprv8ZgxMBicQKsPdy6LMhUtFHAgpocR8GC6QmwMSFpZs7h6Eziw3SpThFfczTDh5rW2krkqffa11UpX3XkeTTB2FvzZKWXqPY54Y6Rq4AQ5R8L/84\u0026#39;/0\u0026#39;/0\u0026#39;/1/*)\u0026#34;; let wallet: OfflineWallet\u0026lt;_\u0026gt; = Wallet::new_offline( external_descriptor, Some(internal_descriptor), Network::Testnet, MemoryDatabase::new(), )?; Ok(()) } Once we have our Wallet instance we can generate a new address and print it out:\n// ...  println!(\u0026#34;Generated Address: {}\u0026#34;, wallet.get_new_address()?); Building and running this code will print out:\nGenerated Address: tb1q7w0t936xp5p994qx506xj53gjdcmzjr2mkqghn Before we\u0026rsquo;ve talked about the benefits of an air-gapped wallet, but we should also talk about the disadvantages: the biggest one is the fact that it cannot create new transactions because it doesn\u0026rsquo;t know which UTXOs belong to the wallet. To get this information we generally need to sync with the network, but this wallet can\u0026rsquo;t physically do that.\nTo fix this we can add one more component to our Wallet: a Blockchain backend. In particular, we are going to use the ElectrumBlockchain which syncs with an Electrum server, since that\u0026rsquo;s available out of the box in BDK and is pretty fast.\nWe can change our Wallet construction to look something like this:\nuse bdk::blockchain::ElectrumBlockchain; use bdk::electrum_client::Client; // ...  let wallet = Wallet::new( external_descriptor, Some(internal_descriptor), Network::Testnet, MemoryDatabase::new(), ElectrumBlockchain::from(Client::new(\u0026#34;ssl://electrum.blockstream.info:60002\u0026#34;).unwrap()), )?; This piece of code is very similar to the one we wrote before, but this time we are using the Wallet::new() constructor instead of Wallet::new_offline(), and this takes an extra argument for the Blockchain type to use. Specifically here, we create an ElectrumBlockchain and connect to Blockstream\u0026rsquo;s public Electrum Testnet servers over SSL.\nNow, since we are running in the Testnet network, we can try to get some funds from a faucet online to this address we\u0026rsquo;ve generated. Once we have an incoming transaction we can do the first sync of our online wallet. this is again something that might seem counterintuitive at first: why do we have to manually ask the Wallet to sync itself? Can\u0026rsquo;t it do it periodically in background? The answer is that yes, that would definitely be possible, but it would remove some control on what\u0026rsquo;s happening inside the wallet from the user. This can be especially problematic on mobile platforms, where the OS tries very aggressively to suspend apps in background to save battery. Having a thread running and trying to make network requests while the app is in background would very likely cause errors or potentially crashes somewhere. So for this reason this operation has to be performed manually, to allow the user to call that function only at the right time.\nuse bdk::blockchain::noop_progress; // ...  wallet.sync(noop_progress(), None)?; In this case, we are not interested in receiving updates about the progress, and we just want to use the default settings, so we use noop_progress() and None as arguments. This will make queries to the Electrum server and store the list of transactions and UTXOs in our Database. In this case, we are using a MemoryDatabase, so those data are only going to be kept in RAM and dropped once our Wallet is dropped. This is very useful for playing around and experimenting, but not so great for real-world wallets: for that, you can use sled which is supported out of the box, or even use a custom database. More on that later!\nSo now that we\u0026rsquo;ve synced with the blockchain we can create our first transaction. First of all, we will print out the balance of our wallet to make sure that our wallet has seen the incoming transaction. Then we will create the actual transaction and we will specify some flags using the TxBuilder. To finish it off, we will ask the wallet to sign the transaction and then broadcast it to the network.\nRight now we will not get into details of all the available options in TxBuilder since that is definitely out of the scope of a \u0026ldquo;getting started\u0026rdquo; guide. For now, you can just imagine the builder as your way to tell the library how to build transactions. We\u0026rsquo;ll come back to this in a future article.\nuse std::str::FromStr; use bdk::bitcoin::Address; use bdk::TxBuilder; // ...  let balance = wallet.get_balance()?; println!(\u0026#34;Wallet balance in SAT: {}\u0026#34;, balance); let faucet_address = Address::from_str(\u0026#34;mkHS9ne12qx9pS9VojpwU5xtRd4T7X7ZUt\u0026#34;)?; let (unsigned_psbt, tx_details) = wallet.create_tx( TxBuilder::with_recipients(vec![(faucet_address.script_pubkey(), balance / 2)]) .enable_rbf(), )?; println!(\u0026#34;Transaction details: {:#?}\u0026#34;, tx_details); In this case, we are sending back half the balance to the faucet\u0026rsquo;s address and we are also enabling RBF since the default fees are at 1 satoshi/vbyte. With RBF we will be able to bump the fees of the transaction, should it get stuck in the mempool due to the low fee rate.\nAll that\u0026rsquo;s left to do once we have our unsigned PSBT is to sign it:\n// ...  let (signed_psbt, tx_finalized) = wallet.sign(unsigned_psbt, None)?; assert!(tx_finalized, \u0026#34;Tx has not been finalized\u0026#34;); And then broadcast it:\n// ...  let raw_transaction = signed_psbt.extract_tx(); let txid = wallet.broadcast(raw_transaction)?; println!( \u0026#34;Transaction sent! TXID: {txid}.\\nExplorer URL: https://blockstream.info/testnet/tx/{txid}\u0026#34;, txid = txid ); Custom Database and Blockchain types We briefly mentioned before that for our example we used the MemoryDatabase, but that it could also be swapped for a different one: this is one example of the modularity of BDK. By default, some database types are implemented in the library, namely (as of now) the MemoryDatabase which only keeps data in RAM and the sled database that can store data on a filesystem. But since the Database trait is public, users of the library can also implement different database types more suitable for their use-case.\nThe same is true for the Blockchain types: the library provides (through the use of opt-in features) implementations for the Electrum, Esplora and CompactFilters (Neutrino) backends. Those again can also be swapped with custom types if the user desires to do so.\nConclusion Hopefully, this article will help you get started with BDK! This is just a very quick and gentle introduction to the library, and only barely scratches the surface of what\u0026rsquo;s inside: we will keep publishing more articles in the future to explain some of the more advanced features of BDK, like key generation, using complex descriptors with multiple keys and/or timelocks, using external signers, etc.\nIf you\u0026rsquo;d like to learn more about the library feel free to ask any questions in the comment section down below, or join our Discord Community to chat with us directly!\n"
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/descriptor/",
	"title": "descriptor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/2020/11/descriptors-in-the-wild/",
	"title": "Descriptors in the wild",
	"tags": ["guide", "descriptor"],
	"description": "Guide to setup a 2-of-2 multisig using Bitcoin Core and BDK",
	"content": "I have tried to setup a 2 of 2 multi signature infrastructure with two different wallets, which know nothing about each other, but are compliant with two very important protocols: Output Descriptors and Partially Signed Bitcoin Transactions described in BIP 174.\nBefore these two protocols came into existence, making a multi signature setup and spending from it was possible only if the involved parties were using the same wallet (eg. Electrum Desktop Wallet). This limitation was due to the fact that the two parties had to agree:\n on the particular type of script and address to use on the way the transaction would be shared composed and signed with all the involved parties.  Output Descriptors are a way to express which kind scriptPubKey and addresses to produce with a key or a serie of keys.\nPSBT is instead the standard protocol used to create transaction and to enrich it with the necessary signatures and other components, to make it valid and complete.\nTogether they provide a common ground to create and use a multi signature infrastructure in a eterogeneous environment and this is what I have put to test.\nThe use case Imagine Alice and Bob owning a company and being willing to put the corporate cash in a 2of2 multi signature setup, so that each one of them have to agree and sign each transaction.\nThe role of Descriptors If Alice and Bob cannot agree on the software to use, to monitor the same financial situation, the two software must control and produce exactly the same series of multisignature addresses.\nTo make two different software produce the same addresses in a deterministic way we must ensure that they:\n produce the same pair of public keys combine them in the same order put them inside the same scriptPubKey to produce the same address  Here is where the Output Descriptors come into play. They describe:\n the sequence of public keys each extended key (xpub) will produce the sequence in which the new public keys of various parties will enter into the script the type of script the wallet will prepare with that group keys and so the type of address the group of keys will produce.  By sharing the same Descriptor, every compliant wallet will derive deterministically the same serie of multisig addresses.\nImmagine Alice using Bitcoin Core (from now on \u0026ldquo;Core\u0026rdquo;) as a Wallet and Bob using a \u0026ldquo;Last generation\u0026rdquo; wallet, Bitcoin Development Kit (from now on \u0026ldquo;BDK\u0026rdquo;), which uses descriptors and miniscript natively.\nEach of these two software wallet should be able to:\n Create a new address which is seen as belonging to the multi signature wallet in both software Express the consent of each party by partially sign the transaction in a way the other wallet can understand and complete it with its own signature.  The infrastructure of multiple Extended keys combined toghether to produce multiple multisignature addresses is often referred as Hierarchical Deterministic multi signature wallet or HDM.\nWhat follows are the steps to create the HDM usable both in Core and in BDK.\nNote: In Core, Descriptor wallets are still experimental and in general, both wallets should be tested for descriptor capabilities only in testnet.\nOur playground We will build a 2of2 key set up that will be used cooperatively by Bitcoin Core and Bitcoin Development Kit. The steps Alice and Bob will do are:\n creation of the seed and the derived Extended Master Public and send it to the other party Create the multi signature descriptor for each wallet Use each other\u0026rsquo;s software to receive testnet coins from a faucet return part of the coins to the faucet signing the transaction with both wallets.  We need:\n Bitcoin Dev Kit Bitcoin Core (at the present moment it is necessary to build one of the last commits on the main branch) Pycoin ku utility  1. Creating the seeds and the derived Extended Public keys Seeds and Extended Master Public We build an Extended Private Master Key for both wallet and derive a BIP84 Extended Master Public for Bitcoin Core and then for BDK.\nFor Bitcoin Core (Alice):\n# new Extended wallet data export core_key=$(ku -n XTN -j create) # New Extended Master Private export core_xprv=$(echo $core_key|jq -r '.wallet_key') # Derived Extended Pubblic key export core_xpub_84=$(ku -j -s 84H/0H/0H $core_xprv |jq -r '.public_version') export core_fingerprint=$(echo $core_key|jq -r '.fingerprint') # Now I build the xpubs (one for receiving and one for the change) # together with informations about the derivation path to be communicated # to BDK wallet's owner (Bob). export core_xpub_84_for_rec_desc=\u0026quot;[$core_fingerprint/84'/0'/0']$core_xpub_84/0/*\u0026quot; export core_xpub_84_for_chg_desc=\u0026quot;[$core_fingerprint/84'/0'/0']$core_xpub_84/1/*\u0026quot; For BDK (Bob) we do the same:\n# new Extended wallet data export BDK_key=$(ku -n XTN -j create) # New Extended Master Private export BDK_xprv=$(echo $BDK_key|jq -r '.wallet_key') # Derived Extended Pubblic key export BDK_xpub_84=$(ku -j -s 84H/0H/0H $BDK_xprv |jq -r '.public_version') export BDK_fingerprint=$(echo $BDK_key|jq -r '.fingerprint') # Now I build the derived xpubs to be communicated (to Alice). export BDK_xpub_84_for_rec_desc=\u0026quot;[$BDK_fingerprint/84'/0'/0']$BDK_xpub_84/0/*\u0026quot; export BDK_xpub_84_for_chg_desc=\u0026quot;[$BDK_fingerprint/84'/0'/0']$BDK_xpub_84/1/*\u0026quot; 2. Creation of the multi signature descriptor for each wallet To build a multisig wallet, each wallet owner must compose the descriptor adding:\n his derived extended private key AND all the extended public keys of the other wallets involved in the multi signature setup  The different nature of the two keys (one is private and one is public) is due to the fact that each wallet, to be able to partially sign the transaction, must manage the private key of the wallet\u0026rsquo;s owner AND have the other party\u0026rsquo;s public key. Otherwise if we put both public key, we would obtain a watch-only wallet unable to sign the transactions. If we had both extended private keys inside the descriptor, we would allow each party to finalize the transactions autonomously.\nIn Bitcoin Core: In our case, the multi signature descriptor for Bitcoin Core will be composed with:\n The BIP84 derived Extended Public Key from BDK The BIP84 derived Extended Private Key from Core.  BDK wallet\u0026rsquo;s owner will send to Core\u0026rsquo;s owner the derived xpub for this purpose. This is how the Core\u0026rsquo;s multisig descriptor will be created and put into an environment variable:\nexport core_rec_desc=\u0026quot;wsh(multi(2,$BDK_xpub_84_for_rec_desc,$core_xprv/84'/0'/0'/0/*))\u0026quot; Where of course $BDK_xpub_84_for_rec_descis the derived master public created in BDK and received by Core\u0026rsquo;s owner.\nThe meaning of what is before and after is illustrated in the doc that explain the use of Output Descriptors in Bitcoin Core.\nWe add the necessary checksum using the specific bitcoin-cli call.\nexport core_rec_desc_chksum=$core_rec_desc#$(bitcoin-cli -testnet getdescriptorinfo $core_rec_desc|jq -r '.checksum') We repeat the same to build the descriptor to receive the change.\nexport core_chg_desc=\u0026quot;wsh(multi(2,$BDK_xpub_84_for_chg_desc,$core_xprv/84'/0'/0'/1/*))\u0026quot; export core_chg_desc_chksum=$core_chg_desc#$(bitcoin-cli -testnet getdescriptorinfo $core_chg_desc|jq -r '.checksum') In BDK: For BDK we set the derivation for receiving addresses and change addresses in the command line (maybe setting an alias)\nBuilding the descriptor:\nexport BDK_rec_desc=\u0026quot;wsh(multi(2,$BDK_xprv/84'/0'/0'/0/*,$core_xpub_84_for_rec_desc))\u0026quot;` Please note that the order of the extended key in the descriptor MUST be the same in the 2 wallets.\nWe have chosen to put BDK first and in each software wallet, the public key derived from BDK will always come first. In alternative, we could have chosen to produce the descriptor, chosing a soretedmulti multisignature setup.\nexport BDK_rec_desc_chksum=$BDK_rec_desc#$(bitcoin-cli -testnet getdescriptorinfo $BDK_rec_desc|jq -r '.checksum') export BDK_chg_desc=\u0026quot;wsh(multi(2,$BDK_xprv/84'/0'/0'/1/*,$core_xpub_84_for_chg_desc))\u0026quot; export BDK_chg_desc_chksum=$BDK_chg_desc#$(bitcoin-cli -testnet getdescriptorinfo $BDK_chg_desc|jq -r '.checksum') To take a look at the variables we have produced so far:\nenv |grep 'core_' env |grep 'BDK_' Now we will use the multisig descriptor wallet to receive testnet coins with Alice and Bob\u0026rsquo;s software\n3. Use each other\u0026rsquo;s software to receive testnet coins from a faucet In Bitcoin Core Alice must create an empty, experimental new \u0026ldquo;descriptors wallet\u0026rdquo; in Core and to import the multisig Output Descriptor.\nbitcoin-cli -testnet createwallet \u0026quot;multisig2of2withBDK\u0026quot; false true \u0026quot;\u0026quot; false true false The flag are to:\n use the private keys make it empty no password provided to the wallet reusing of addresses not allowed \u0026ldquo;new experimental descriptors wallet\u0026rdquo; don\u0026rsquo;t load it on start up  bitcoin-cli -testnet -rpcwallet=multisig2of2withBDK importdescriptors \u0026quot;[{\\\u0026quot;desc\\\u0026quot;:\\\u0026quot;$core_rec_desc_chksum\\\u0026quot;,\\\u0026quot;timestamp\\\u0026quot;:\\\u0026quot;now\\\u0026quot;,\\\u0026quot;active\\\u0026quot;:true,\\\u0026quot;internal\\\u0026quot;:false},{\\\u0026quot;desc\\\u0026quot;:\\\u0026quot;$core_chg_desc_chksum\\\u0026quot;,\\\u0026quot;timestamp\\\u0026quot;:\\\u0026quot;now\\\u0026quot;,\\\u0026quot;active\\\u0026quot;:true,\\\u0026quot;internal\\\u0026quot;:true}]\u0026quot; Now Alice asks for her first receiving multisignature address.\nexport first_address=$(bitcoin-cli -testnet -rpcwallet=multisig2of2withBDK getnewaddress) echo $first_address BDK In BDK Bob can specify directly the descriptors on the command line to produce the multisig address, because BDK is descriptors aware natively.\nrepl -d \u0026quot;$BDK_rec_desc_chksum\u0026quot; -c \u0026quot;$BDK_chg_desc_chksum\u0026quot; -n testnet -w $BDK_fingerprint get_new_address` Et voil√†: if we have done everything correctly, the newly created address in Core is the same of the newly created address in BDK. this is part of the \u0026ldquo;miracle\u0026rdquo; of descriptors' interoperability.\nWe ask for testnet coins giving the first created address. To find testnet coins for free, you can just google \u0026ldquo;testnet faucet\u0026rdquo; and you should find some satoshis to play with. Just give to the site your first generated address and, in twenty minutes, you will find the satoshis in your balance both in Core and in BDK.\n# to check it in Core: bitcoin-cli -testnet -rpcwallet=multisig2of2withBDK getbalance # In BDK: # Sync with the blockchain repl -d \u0026quot;$BDK_rec_desc_chksum\u0026quot; -c \u0026quot;$BDK_chg_desc_chksum\u0026quot; -n testnet -w $BDK_fingerprint sync # Get the balance repl -d \u0026quot;$BDK_rec_desc_chksum\u0026quot; -c \u0026quot;$BDK_chg_desc_chksum\u0026quot; -n testnet -w $BDK_fingerprint get_balance Some testnet faucets have an address to send back the unused satoshi after the use. Take note of that because we will use it in the next step.\n4. we return part of the satoshis received back to the faucet export psbt=$(bitcoin-cli -testnet -rpcwallet=multisig2of2withBDK walletcreatefundedpsbt \u0026quot;[]\u0026quot; \u0026quot;[{\\\u0026quot;tb1qrcesfj9f2d7x40xs6ztnlrcgxhh6vsw8658hjdhdy6qgkf6nfrds9rp79a\\\u0026quot;:0.000012}]\u0026quot;|jq -r '.psbt') export psbt=$(bitcoin-cli -testnet -rpcwallet=multisig2of2withBDK walletprocesspsbt $psbt|jq -r '.psbt') { \u0026quot;psbt\u0026quot;: \u0026quot;cHNidP8BAIkCAAAAATj90EC+NAuXj7y6SseZJucoJM6sGnUcVm9koTveZECTAAAAAAD+////AmACAAAAAAAAIgAg98ol9j4AalD71E0mV5QV0uM6/vCT+pi2twxr/zrvLROwBAAAAAAAACIAIB4zBMipU3xqvNDQlz+PCDXvpkHH1Q95Nu0mgIsnU0jbAAAAAAABAIkCAAAAAQS+ObgGG6UwtvaO3KYph2E3/ws7Q83RbmR3rxC0fKYSAQAAAAD+////AtAHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNDAHQAAAAAAACIAIBQpiDTgPIMt0ld8cmuYqlY+EIPjvrmMqZruDhs61hQNAAAAAAEBK9AHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNAiAgNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfUcwRAIgS6x0i1J1HRzllIPf4WlFY+Dl8kCCLK81TL2djZxTFXMCICJVBKkKNxu1w1mRVor6iFTSVXiJjmWwBXVeJLISvBwAAQEFR1IhArn3tec7n7318rnWqf0dIIwtLtfxo6Zt0HV70UvZYaWvIQNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfVKuIgYCufe15zufvfXyudap/R0gjC0u1/Gjpm3QdXvRS9lhpa8YNEw2cFQAAIAAAACAAAAAgAAAAAAAAAAAIgYDbdI+wHtIgO6pS6Ja7jai1pDwPeidKoDCytTO1jhjAH0YO/laXFQAAIAAAACAAAAAgAAAAAAAAAAAAAEBR1IhAqccvA3rL13D1K4GeWjcahDsO3P8oaVNBttk4MlCKXIcIQLHKhjmPuCQjyS77ZfaMN2tdgNKcf/+57VXGZhz/UWTl1KuIgICpxy8DesvXcPUrgZ5aNxqEOw7c/yhpU0G22TgyUIpchwYNEw2cFQAAIAAAACAAAAAgAEAAAADAAAAIgICxyoY5j7gkI8ku+2X2jDdrXYDSnH//ue1VxmYc/1Fk5cYO/laXFQAAIAAAACAAAAAgAEAAAADAAAAAAA=\u0026quot;, \u0026quot;complete\u0026quot;: false } Exactly! Note the \u0026quot;complete\u0026quot;: false. We have processed the transaction with Core but we miss one of the necessary key of the multisig 2of2 setup (The one contained inside BDK).\ntb1qrcesfj9f2d7x40xs6ztnlrcgxhh6vsw8658hjdhdy6qgkf6nfrds9rp79a is the address we got from the faucet site to return the satoshis.\nThe PSBT is sent over to the BDK wallet owner who tries to sign the transaction:\nrepl -d \u0026quot;$BDK_rec_desc_chksum\u0026quot; -c \u0026quot;$BDK_chg_desc_chksum\u0026quot; -n testnet -w $BDK_fingerprint sign --psbt $psbt { \u0026quot;is_finalized\u0026quot;: true, \u0026quot;psbt\u0026quot;: \u0026quot;cHNidP8BAIkCAAAAATj90EC+NAuXj7y6SseZJucoJM6sGnUcVm9koTveZECTAAAAAAD+////AmACAAAAAAAAIgAg98ol9j4AalD71E0mV5QV0uM6/vCT+pi2twxr/zrvLROwBAAAAAAAACIAIB4zBMipU3xqvNDQlz+PCDXvpkHH1Q95Nu0mgIsnU0jbAAAAAAABAIkCAAAAAQS+ObgGG6UwtvaO3KYph2E3/ws7Q83RbmR3rxC0fKYSAQAAAAD+////AtAHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNDAHQAAAAAAACIAIBQpiDTgPIMt0ld8cmuYqlY+EIPjvrmMqZruDhs61hQNAAAAAAEBK9AHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNAiAgNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfUcwRAIgS6x0i1J1HRzllIPf4WlFY+Dl8kCCLK81TL2djZxTFXMCICJVBKkKNxu1w1mRVor6iFTSVXiJjmWwBXVeJLISvBwAASICArn3tec7n7318rnWqf0dIIwtLtfxo6Zt0HV70UvZYaWvRzBEAiBkVDLgVEwvENnLx+04o7gGpGjFDBwAXTJmf8Yvo35oygIgbuBkHsvPC9jmZcMZ9P+Pwp01yxSaWo+5feyPmd3ai1kBAQVHUiECufe15zufvfXyudap/R0gjC0u1/Gjpm3QdXvRS9lhpa8hA23SPsB7SIDuqUuiWu42otaQ8D3onSqAwsrUztY4YwB9Uq4iBgNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfRg7+VpcVAAAgAAAAIAAAACAAAAAAAAAAAAiBgK597XnO5+99fK51qn9HSCMLS7X8aOmbdB1e9FL2WGlrxg0TDZwVAAAgAAAAIAAAACAAAAAAAAAAAABBwABCNoEAEcwRAIgZFQy4FRMLxDZy8ftOKO4BqRoxQwcAF0yZn/GL6N+aMoCIG7gZB7LzwvY5mXDGfT/j8KdNcsUmlqPuX3sj5nd2otZAUcwRAIgS6x0i1J1HRzllIPf4WlFY+Dl8kCCLK81TL2djZxTFXMCICJVBKkKNxu1w1mRVor6iFTSVXiJjmWwBXVeJLISvBwAAUdSIQK597XnO5+99fK51qn9HSCMLS7X8aOmbdB1e9FL2WGlryEDbdI+wHtIgO6pS6Ja7jai1pDwPeidKoDCytTO1jhjAH1SrgABAUdSIQKnHLwN6y9dw9SuBnlo3GoQ7Dtz/KGlTQbbZODJQilyHCECxyoY5j7gkI8ku+2X2jDdrXYDSnH//ue1VxmYc/1Fk5dSriICAqccvA3rL13D1K4GeWjcahDsO3P8oaVNBttk4MlCKXIcGDRMNnBUAACAAAAAgAAAAIABAAAAAwAAACICAscqGOY+4JCPJLvtl9ow3a12A0px//7ntVcZmHP9RZOXGDv5WlxUAACAAAAAgAAAAIABAAAAAwAAAAAA\u0026quot; } The signature has succeded (note the \u0026ldquo;is_finalized\u0026rdquo;: true,) and now we can broadcast the transction.\nrepl -d \u0026quot;$BDK_rec_desc_chksum\u0026quot; -c \u0026quot;$BDK_chg_desc_chksum\u0026quot; -n testnet -w $BDK_fingerprint broadcast --psbt \u0026quot;cHNidP8BAIkCAAAAATj90EC+NAuXj7y6SseZJucoJM6sGnUcVm9koTveZECTAAAAAAD+////AmACAAAAAAAAIgAg98ol9j4AalD71E0mV5QV0uM6/vCT+pi2twxr/zrvLROwBAAAAAAAACIAIB4zBMipU3xqvNDQlz+PCDXvpkHH1Q95Nu0mgIsnU0jbAAAAAAABAIkCAAAAAQS+ObgGG6UwtvaO3KYph2E3/ws7Q83RbmR3rxC0fKYSAQAAAAD+////AtAHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNDAHQAAAAAAACIAIBQpiDTgPIMt0ld8cmuYqlY+EIPjvrmMqZruDhs61hQNAAAAAAEBK9AHAAAAAAAAIgAg6GXadcNj7k4yKUbnVlTLiedXQFXYdCBoNygop/PISNAiAgNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfUcwRAIgS6x0i1J1HRzllIPf4WlFY+Dl8kCCLK81TL2djZxTFXMCICJVBKkKNxu1w1mRVor6iFTSVXiJjmWwBXVeJLISvBwAASICArn3tec7n7318rnWqf0dIIwtLtfxo6Zt0HV70UvZYaWvRzBEAiBkVDLgVEwvENnLx+04o7gGpGjFDBwAXTJmf8Yvo35oygIgbuBkHsvPC9jmZcMZ9P+Pwp01yxSaWo+5feyPmd3ai1kBAQVHUiECufe15zufvfXyudap/R0gjC0u1/Gjpm3QdXvRS9lhpa8hA23SPsB7SIDuqUuiWu42otaQ8D3onSqAwsrUztY4YwB9Uq4iBgNt0j7Ae0iA7qlLolruNqLWkPA96J0qgMLK1M7WOGMAfRg7+VpcVAAAgAAAAIAAAACAAAAAAAAAAAAiBgK597XnO5+99fK51qn9HSCMLS7X8aOmbdB1e9FL2WGlrxg0TDZwVAAAgAAAAIAAAACAAAAAAAAAAAABBwABCNoEAEcwRAIgZFQy4FRMLxDZy8ftOKO4BqRoxQwcAF0yZn/GL6N+aMoCIG7gZB7LzwvY5mXDGfT/j8KdNcsUmlqPuX3sj5nd2otZAUcwRAIgS6x0i1J1HRzllIPf4WlFY+Dl8kCCLK81TL2djZxTFXMCICJVBKkKNxu1w1mRVor6iFTSVXiJjmWwBXVeJLISvBwAAUdSIQK597XnO5+99fK51qn9HSCMLS7X8aOmbdB1e9FL2WGlryEDbdI+wHtIgO6pS6Ja7jai1pDwPeidKoDCytTO1jhjAH1SrgABAUdSIQKnHLwN6y9dw9SuBnlo3GoQ7Dtz/KGlTQbbZODJQilyHCECxyoY5j7gkI8ku+2X2jDdrXYDSnH//ue1VxmYc/1Fk5dSriICAqccvA3rL13D1K4GeWjcahDsO3P8oaVNBttk4MlCKXIcGDRMNnBUAACAAAAAgAAAAIABAAAAAwAAACICAscqGOY+4JCPJLvtl9ow3a12A0px//7ntVcZmHP9RZOXGDv5WlxUAACAAAAAgAAAAIABAAAAAwAAAAAA\u0026quot; { \u0026quot;txid\u0026quot;: \u0026quot;a0b082e3b0579822d4a0b0fa95a4c4662f6b128ffd43fdcfe53c37473ce85dee\u0026quot; } Conclusion We have built an HDM and we have used it with two indipendent wallets, which are compatible with BIP 174 and Output Descriptors. Hopefully we will see many other compatible wallets beyound Bitcoin Core and BDK, with which we will be able to easily set up multi signature schemes.\n"
},
{
	"uri": "https://bitcoindevkit.org/blog/author/gabriele-domenichini/",
	"title": "Gabriele Domenichini",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/blog/tags/guide/",
	"title": "guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://bitcoindevkit.org/",
	"title": "Home",
	"tags": [],
	"description": "",
	"content": "Bitcoin Dev Kit The Bitcoin Dev Kit (BDK) project (originally called Magical Bitcoin üßô) aims to build a collection of tools and libraries that are designed to be a solid foundation for cross platform Bitcoin wallets, along with a fully working reference implementation wallet called Magical Bitcoin. All BDK components are designed to be lightweight and modular so that they can be adapted for virtually any use-case: from single-sig mobile wallets to multi-billion-dollar cold storage vaults.\nThe main long-term goal is to concentrate the development efforts of multiple people and companies into one open source and very well reviewed project, instead of dispersing them over multiple closed/semi-closed or poorly designed projects.\nWhile some parts of the library are still considered \u0026ldquo;experimental\u0026rdquo; (check the docs for more info), the core Wallet architecture is now considered stable. We still can\u0026rsquo;t commit to keeping this same exact API forever, but we are not expecting to do any major breaking change in that area.\nIf you want to try out the library for your projects, now it\u0026rsquo;s finally a good time to do it! You can start by checking out the \u0026ldquo;getting started\u0026rdquo; section in our blog or joining our Discord server to chat with us.\nPlayground As a way of demonstrating the flexibly of this project, a minimalistic command line tool (called bdk-cli) is available as a debugging tool in the bdk-cli repo. It has been compiled to WebAssembly and can be used directly from the browser. See the playground section to give it a try!\nThe playground relies on Esplora to monitor the blockchain and is currently locked in testnet-only mode, for obvious safety reasons. The native command line tool can also be used in regtest mode when installed on a computer. See the bdk-cli section to learn more.\nDescriptors One of the original milestones of this project was to provide wallets with \u0026ldquo;almost magically\u0026rdquo; support for very complex spending policies, without having to individually translate them into code. It may sound disappointing, but there isn\u0026rsquo;t, in fact, any real magic in this wallet: the generalization is achieved thanks to descriptors, that are now slowly starting to see adoption in a few other Bitcoin projects as well.\nThe author of this project strongly believes descriptors will be a big part of the future generation of Bitcoin wallets, since they provide a very flexible scripting language that can also be extended as the technology and tooling of Bitcoin evolves and changes (Schnorr signatures, Taproot, etc).\nTo learn more, check out the specific Descriptors section.\n"
}]