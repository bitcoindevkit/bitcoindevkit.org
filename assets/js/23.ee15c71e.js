(window.webpackJsonp=window.webpackJsonp||[]).push([[23],{443:function(e,t,s){"use strict";s.r(t);var n=s(18),a=Object(n.a)({},(function(){var e=this,t=e.$createElement,s=e._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("This is the first of a two-parts blog series in which I will try to explain all the changes that I made to BDK (and some of its dependencies) to make our "),s("a",{attrs:{href:"https://twitter.com/afilini/status/1459763243556163584",target:"_blank",rel:"noopener noreferrer"}},[e._v("first Taproot transaction in mainnet"),s("OutboundLink")],1),e._v(", which also\nturned out to be "),s("a",{attrs:{href:"https://twitter.com/afilini/status/1459774394054725634",target:"_blank",rel:"noopener noreferrer"}},[e._v("the first ever use of the new "),s("code",[e._v("OP_CHECKSIGADD")]),e._v(" opcode"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("p",[e._v("Hopefully this will give an insight into what kind of changes need to be made to a wallet in order to support spending "),s("code",[e._v("P2TR")]),e._v(" outputs, both with key-spend and script-spend. BDK actually delegates\nmost of the hard work to "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-miniscript",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-miniscript"),s("OutboundLink")],1),e._v(", and luckily most of the Taproot code was already implemented by the time I started working on it. I only had to patch a few little bugs here and there, and it ended up\nworking flawlessly in the end.")]),e._v(" "),s("p",[e._v("In this first part I will focus on the changes made to our dependencies, "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-bitcoin",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-bitcoin"),s("OutboundLink")],1),e._v(" and "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-miniscript",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-miniscript"),s("OutboundLink")],1),e._v(". In the second part I will talk about BDK itself.")]),e._v(" "),s("h2",{attrs:{id:"backstory"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#backstory"}},[e._v("#")]),e._v(" Backstory")]),e._v(" "),s("p",[e._v("On the evening of Thursday, November 11th I was attending our weekly "),s("a",{attrs:{href:"https://www.satoshispritz.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Satoshi Spritz"),s("OutboundLink")],1),e._v(" meetup in Milan. The activation of Taproot was right around the corner, and naturally that was the main discussion\ntopic that night. The activation was forecasted for the early afternoon of Sunday, November 14th, a little less than 72h later.")]),e._v(" "),s("p",[e._v("I began to wonder how hard it would be to patch BDK and add support for Taproot. I knew most of the work had already been done in our main dependencies, "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-bitcoin",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-bitcoin"),s("OutboundLink")],1),e._v(" and "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-miniscript",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-miniscript"),s("OutboundLink")],1),e._v(", and so I decided\nto challenge myself: could I make it in time for the activation?")]),e._v(" "),s("p",[e._v('The following day I started digging into the topic. It didn\'t help that up until that time I only had a rather "high level" idea of how Taproot worked, but luckily all the BIPs were very well written and\nstraightforward to understand.')]),e._v(" "),s("p",[e._v("By Friday night (or rather, early Saturday morning) "),s("a",{attrs:{href:"https://mempool.space/signet/tx/ba0ebb350717701ca4ea109aadfbaf3058f6cd73e5ece3927ddee653de06cf5a",target:"_blank",rel:"noopener noreferrer"}},[e._v("I had Taproot key-spend working"),s("OutboundLink")],1),e._v(", which made me pretty optimistic even though the activation date was actually moving closer, now being forecasted for\nSunday "),s("em",[e._v("morning")]),e._v(".")]),e._v(" "),s("p",[e._v("After a few hours of sleep I went back to work and by early Saturday afternoon "),s("a",{attrs:{href:"https://mempool.space/signet/tx/41d7d49f9f4edffa9ca88ad6fb887fbf1ae68f9f31def267fdb3a5949f766bf5",target:"_blank",rel:"noopener noreferrer"}},[e._v("I had Taproot script-spend working as well"),s("OutboundLink")],1),e._v(". This left me a few hours to coordinate with some friends and "),s("a",{attrs:{href:"https://mempool.space/address/1Taproote7gvQGKz5g982ecSbPvqJhMUf",target:"_blank",rel:"noopener noreferrer"}},[e._v("generate a vanity address"),s("OutboundLink")],1),e._v("\nto deposit funds into temporarily, as we didn't trust sending them to Taproot addresses before the activation (as they were anyone-can-spend according to the pre-activation rules).")]),e._v(" "),s("p",[e._v("After another pretty short night, I woke up a 5:30 AM on Sunday to monitor the activation. I broadcasted our transactions shortly after 6:00 AM as the activation block was being mined. Unfortunately, the first\nthree blocks that were enforcing Taproot rules "),s("a",{attrs:{href:"https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2021-November/019598.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("didn't include any Taproot transaction"),s("OutboundLink")],1),e._v(", which indicates that the miners weren't actually running the new Bitcoin Core 22.0 nodes. The fourth block, mined by "),s("code",[e._v("Foundry USA")]),e._v(" "),s("a",{attrs:{href:"https://mempool.space/tx/2eb8dbaa346d4be4e82fe444c2f0be00654d8cfd8c4a9a61b11aeaab8c00b272",target:"_blank",rel:"noopener noreferrer"}},[e._v("included my transaction"),s("OutboundLink")],1),e._v(" and "),s("a",{attrs:{href:"https://twitter.com/achow101/status/1459760452775387136?s=20",target:"_blank",rel:"noopener noreferrer"}},[e._v("a few others"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("p",[e._v("In the end our transaction was the third Taproot script-spend in the block, but the first to use the new "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0342.mediawiki#script-execution",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("OP_CHECKSIGADD")]),s("OutboundLink")],1),e._v(" opcode, as the two preceding it were respectively "),s("a",{attrs:{href:"https://mempool.space/tx/37777defed8717c581b4c0509329550e344bdc14ac38f71fc050096887e535c8",target:"_blank",rel:"noopener noreferrer"}},[e._v("a single-sig"),s("OutboundLink")],1),e._v(" and "),s("a",{attrs:{href:"https://mempool.space/tx/905ecdf95a84804b192f4dc221cfed4d77959b81ed66013a7e41a6e61e7ed530",target:"_blank",rel:"noopener noreferrer"}},[e._v("a 2-of-2 multisig"),s("OutboundLink")],1),e._v("\nscript, made with with two "),s("code",[e._v("OP_CHECKSIG(VERIFY)")]),e._v("s.")]),e._v(" "),s("p",[e._v("Now, with the context out of the way, we can begin talking about the code!")]),e._v(" "),s("h2",{attrs:{id:"rust-bitcoin"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rust-bitcoin"}},[e._v("#")]),e._v(" rust-bitcoin")]),e._v(" "),s("p",[e._v("The first dependency I had to update was "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-bitcoin",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-bitcoin"),s("OutboundLink")],1),e._v(". Most of the taproot stuff were already merged in "),s("code",[e._v("master")]),e._v(" (altough they hadn't been released yet). One notable missing part was the support for "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0371.mediawiki",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("BIP371")]),s("OutboundLink")],1),e._v(",\nwhich is an extension of "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0174.mediawiki",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("BIP174")]),s("OutboundLink")],1),e._v(", aka the "),s("code",[e._v("Partially Signed Bitcoin Transaction")]),e._v(" BIP. This new BIP defines a few new fields that are required to properly handle Taproot transactions.")]),e._v(" "),s("p",[e._v("Luckily most of the work had already been done by "),s("a",{attrs:{href:"https://twitter.com/sanket1729",target:"_blank",rel:"noopener noreferrer"}},[e._v("sanket1729"),s("OutboundLink")],1),e._v(", so I forked his branch and made only few very minor changes, just to expose a structure that I will have to use later which in his code wasn't public.")]),e._v(" "),s("p",[e._v("You can find all the commits mentioned here in "),s("a",{attrs:{href:"https://github.com/afilini/rust-bitcoin/tree/taproot-testing",target:"_blank",rel:"noopener noreferrer"}},[e._v("my rust-bitcoin "),s("code",[e._v("taproot-testing")]),e._v(" branch"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git diff 187234f f830df9\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("diff --git a/src/lib.rs b/src/lib.rs\nindex 87d9c36..d5e5802 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/lib.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/lib.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("@@ -54,7 +54,6 @@")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(unused_mut)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(dead_code)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(unused_imports)]\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(missing_docs)]\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(unused_must_use)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(broken_intra_doc_links)]\n")])]),e._v("\ndiff --git a/src/util/taproot.rs b/src/util/taproot.rs\nindex 674eeee..3d56cbc 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/util/taproot.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/util/taproot.rs")]),e._v("\n@@ -440,7 +440,7 @@ impl TaprootBuilder {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("// Internally used structure to represent the node information in taproot tree\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]\n')])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("pub(crate) struct NodeInfo {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("pub struct NodeInfo {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    /// Merkle Hash for this node\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub(crate) hash: sha256::Hash,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    /// information about leaves inside this node\n")])]),e._v("@@ -448,8 +448,12 @@ pub(crate) struct NodeInfo {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("}\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("impl NodeInfo {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn hash(&self) -> &sha256::Hash {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        &self.hash\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    // Create a new NodeInfo with omitted/hidden info\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn new_hidden(hash: sha256::Hash) -> Self {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn new_hidden(hash: sha256::Hash) -> Self {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        Self {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            hash: hash,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            leaves: vec![],\n")])]),e._v("@@ -457,7 +461,7 @@ impl NodeInfo {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    // Create a new leaf with NodeInfo\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn new_leaf_with_ver(script: Script, ver: LeafVersion) -> Self {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn new_leaf_with_ver(script: Script, ver: LeafVersion) -> Self {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        let leaf = LeafInfo::new(script, ver);\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        Self {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            hash: leaf.hash(),\n")])]),e._v("@@ -466,7 +470,7 @@ impl NodeInfo {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    // Combine two NodeInfo's to create a new parent\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn combine(a: Self, b: Self) -> Result<Self, TaprootBuilderError> {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn combine(a: Self, b: Self) -> Result<Self, TaprootBuilderError> {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        let mut all_leaves = Vec::with_capacity(a.leaves.len() + b.leaves.len());\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        for mut a_leaf in a.leaves {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            a_leaf.merkle_branch.push(b.hash)?; // add hashing partner\n")])]),e._v("\n")])])]),s("p",[e._v("There isn't much to explain here: I disabled the "),s("code",[e._v("missing_docs")]),e._v(" lint so that the compiler wouldn't complain about the new public methods that aren't documented.\nThen, I added a getter for the "),s("code",[e._v("hash")]),e._v(" field of "),s("code",[e._v("NodeInfo")]),e._v(" and made the struct itself and a bunch of methods public.")]),e._v(" "),s("p",[e._v('We will use this structure later to recover the merkle root of a Taproot script tree, given one leaf and the other "hidden" branches.')]),e._v(" "),s("h2",{attrs:{id:"rust-miniscript"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rust-miniscript"}},[e._v("#")]),e._v(" rust-miniscript")]),e._v(" "),s("p",[e._v("Moving on to "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-miniscript",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-miniscript"),s("OutboundLink")],1),e._v(': once again, most of the work required to support Taproot had already been done, but this time I was working with very "early" prototype-like code, so I was prepared to\nmake some changes to the code to get it to work how I wanted.')]),e._v(" "),s("p",[e._v("Instead of showing one big diff I will talk about the commits individually, which I think will help making more clear what I was doing.")]),e._v(" "),s("p",[e._v("Once again, you can find all the commits referenced here in "),s("a",{attrs:{href:"https://github.com/afilini/rust-miniscript/tree/taproot",target:"_blank",rel:"noopener noreferrer"}},[e._v("my rust-miniscript "),s("code",[e._v("taproot")]),e._v(" branch"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 34cf15b\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 34cf15b3aac1d8c2693af1b9749b888f3f29e510\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Fri Nov 12 12:06:35 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Fix TapTree iter depth\n")])]),e._v("\ndiff --git a/src/descriptor/tr.rs b/src/descriptor/tr.rs\nindex 79d3c05..314c7f4 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/descriptor/tr.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/descriptor/tr.rs")]),e._v("\n@@ -65,7 +65,7 @@ impl<Pk: MiniscriptKey> TapTree<Pk> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    /// Iterate over all miniscripts\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn iter(&self) -> TapTreeIter<Pk> {\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        TapTreeIter { stack: vec![self] }\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        TapTreeIter { stack: vec![(0, self)] }\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    // Helper function to translate keys\n")])]),e._v("@@ -262,7 +262,7 @@ pub struct TapTreeIter<'a, Pk: MiniscriptKey>\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("where\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    Pk: 'a,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("{\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    stack: Vec<&'a TapTree<Pk>>,\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    stack: Vec<(usize, &'a TapTree<Pk>)>,\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("}\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("impl<'a, Pk> Iterator for TapTreeIter<'a, Pk>\n")])]),e._v("@@ -273,13 +273,13 @@ where\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn next(&mut self) -> Option<Self::Item> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        while !self.stack.is_empty() {\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            let last = self.stack.pop().expect("Size checked above");\n')])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            let (depth, last) = self.stack.pop().expect("Size checked above");\n')])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            match &*last {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                TapTree::Tree(l, r) => {\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    self.stack.push(&r);\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    self.stack.push(&l);\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    self.stack.push((depth + 1, &r));\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    self.stack.push((depth + 1, &l));\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                }\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                TapTree::Leaf(ref ms) => return Some((self.stack.len(), ms)),\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                TapTree::Leaf(ref ms) => return Some((depth, ms)),\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        None\n")])])])])]),s("p",[s("code",[e._v("TapTreeIterator")]),e._v(" is an iterator that goes through a "),s("code",[e._v("TapTree")]),e._v(" and yields a "),s("code",[e._v("(depth, node)")]),e._v(" pair. This is then fed to "),s("a",{attrs:{href:"https://github.com/afilini/rust-miniscript/blob/taproot/src/descriptor/tr.rs#L183-L189",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("TaprootBuilder")]),s("OutboundLink")],1),e._v(", which returns an error if trying to insert nodes\nin "),s("a",{attrs:{href:"https://github.com/afilini/rust-bitcoin/blob/taproot-testing/src/util/taproot.rs#L403-L405",target:"_blank",rel:"noopener noreferrer"}},[e._v("an order that is not DFS"),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("p",[e._v("The way the depth was computed before made the builder always fail for non-trivial trees (i.e. more than 1 node).")]),e._v(" "),s("p",[e._v("Here I decided to play the safe card, and just keep track of the depth explicitly: I think there might be a way to compute the depth just knowing the "),s("code",[e._v("self.stack.len()")]),e._v(" (assuming the tree has a specific structure,\nwhich I'm not sure applies here), but anyway I didn't have much time to think about it and I just went for the \"dumb but idiot-proof\" way which ended up working fine.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show f4a3459\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit f4a3459128e37ca0c2701b8b6da064d4952296ff\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:15:52 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Switch rust-bitcoin rev\n")])]),e._v("\ndiff --git a/Cargo.toml b/Cargo.toml\nindex 12825e8..8240024 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/Cargo.toml")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/Cargo.toml")]),e._v('\n@@ -17,7 +17,7 @@ rand = ["bitcoin/rand"]\n\n'),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("[dependencies]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('# bitcoin = "0.27"\n')])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('bitcoin = {git = "https://github.com/sanket1729/rust-bitcoin", branch = "taproot_psbt"}\n')])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('bitcoin = { git = "https://github.com/afilini/rust-bitcoin.git", branch = "taproot-testing" }\n')])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("[dependencies.serde]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('version = "1.0"\n')])])])])]),s("p",[e._v("Trivial commit, switch to "),s("a",{attrs:{href:"https://github.com/afilini/rust-bitcoin/tree/taproot-testing",target:"_blank",rel:"noopener noreferrer"}},[e._v("my fork of rust-bitcoin"),s("OutboundLink")],1),e._v(" so that I can make changes if necessary.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 0446b16\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 0446b1631cec9f7118d46f0f4c94ccd20de29f94\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:25:18 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Parse x-only keys\n")])]),e._v("\ndiff --git a/src/descriptor/key.rs b/src/descriptor/key.rs\nindex 4108d00..b7f90b5 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/descriptor/key.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/descriptor/key.rs")]),e._v("\n@@ -283,9 +283,9 @@ impl FromStr for DescriptorPublicKey {\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn from_str(s: &str) -> Result<Self, Self::Err> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('        // A "raw" public key without any origin is the least we accept.\n')])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        if s.len() < 66 {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        if s.len() < 64 {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            return Err(DescriptorKeyParseError(\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                "Key too short (<66 char), doesn\'t match any format",\n')])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                "Key too short (<64 char), doesn\'t match any format",\n')])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            ));\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")])]),e._v("\n@@ -301,6 +301,14 @@ impl FromStr for DescriptorPublicKey {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                derivation_path,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                wildcard,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            }))\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        } else if key_part.len() == 64 {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            // x-only pubkey, prefix it with `02`\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            let key = bitcoin::PublicKey::from_str(&format!("02{}", key_part))\n')]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                .map_err(|_| DescriptorKeyParseError("Error while parsing x-only public key"))?;\n')]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Ok(DescriptorPublicKey::SinglePub(DescriptorSinglePub {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                key,\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                origin,\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            }))\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        } else {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            if key_part.len() >= 2\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                && !(&key_part[0..2] == "02" || &key_part[0..2] == "03" || &key_part[0..2] == "04")\n')])]),e._v("diff --git a/src/lib.rs b/src/lib.rs\nindex e168b16..3a2335e 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/lib.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/lib.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("@@ -95,8 +95,6 @@")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(non_snake_case)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(unused_mut)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(dead_code)]\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(unused_imports)]\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("#![deny(missing_docs)]\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("pub extern crate bitcoin;\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('#[cfg(feature = "serde")]\n')])])])])]),s("p",[e._v("This, I'm not really sure of: Taproot uses x-only public keys, which means that the first byte (which is usually a "),s("code",[e._v("03")]),e._v(" or a "),s("code",[e._v("02")]),e._v(") that indicates the parity of the EC point is completely dropped, and it's implicit\nthat the point is even (= "),s("code",[e._v("02")]),e._v("). Check out "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("BIP340")]),s("OutboundLink")],1),e._v(" for a much better explanation.")]),e._v(" "),s("p",[e._v("So here when I find a string that is only 64 characters long I will assume it's an x-only pubkey, and I will parse it as a normal "),s("code",[e._v("bitcoin::PublicKey")]),e._v(" by prefixing it with "),s("code",[e._v("02")]),e._v(".")]),e._v(" "),s("p",[e._v("I guess one alternative could have been to try and parse it as a "),s("code",[e._v("schnorr::PublicKey")]),e._v(' and then "convert" it to a '),s("code",[e._v("ecdsa::PublicKey")]),e._v(" which should be supported, but once again I just wanted to get it done quickly and\nthis worked fine.")]),e._v(" "),s("p",[e._v("I also disabled the "),s("code",[e._v("unused_imports")]),e._v(" and "),s("code",[e._v("missing_docs")]),e._v(" lint so that the compiler wouldn't whine too much.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 87316ff\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 87316fffd06ab3bdf300fd1a958ddaa2789a6696\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:26:01 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Parse `tr()` descriptors\n")])]),e._v("\ndiff --git a/src/descriptor/mod.rs b/src/descriptor/mod.rs\nindex 06d98e1..4190786 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/descriptor/mod.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/descriptor/mod.rs")]),e._v("\n@@ -610,6 +610,7 @@ where\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            ("wpkh", 1) => Descriptor::Wpkh(Wpkh::from_tree(top)?),\n')]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            ("sh", 1) => Descriptor::Sh(Sh::from_tree(top)?),\n')]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            ("wsh", 1) => Descriptor::Wsh(Wsh::from_tree(top)?),\n')])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('            ("tr", _) => Descriptor::Tr(Tr::from_tree(top)?),\n')])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => Descriptor::Bare(Bare::from_tree(top)?),\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        })\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("diff --git a/src/expression.rs b/src/expression.rs\nindex 1cef614..11a68d3 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/expression.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/expression.rs")]),e._v("\n@@ -100,7 +100,12 @@ impl<'a> Tree<'a> {\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                sl = &sl[n + 1..];\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                loop {\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let (arg, new_sl) = Tree::from_slice_helper_round(sl, depth + 1)?;\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let (arg, new_sl) = if sl.contains('{') {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        Tree::from_slice_helper_curly(sl, depth + 1)?\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    } else {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        Tree::from_slice_helper_round(sl, depth + 1)?\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    };\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    ret.args.push(arg);\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    if new_sl.is_empty() {\n")])])])])]),s("p",[e._v("When trying to parse a descriptor (essentially turning a recursive string of "),s("code",[e._v("operator(args)")]),e._v(" into an abstract tree in memory) use a "),s("em",[e._v("curly-bracket-aware")]),e._v(" parser if there is one in the string.")]),e._v(" "),s("p",[e._v("The code to then build a "),s("code",[e._v("Tr")]),e._v(" struct given an "),s("code",[e._v("expression::Tree")]),e._v(" (and the "),s("code",[e._v("from_slice_helper_curly")]),e._v(" function) were already implemented, so it was just a matter of correctly\nbuilding the abstract tree by parsing curly brackets in descriptors.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 3055cab\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 3055cabef8bd51eda344ce501b03c533fd367b4f\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:26:30 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Fix control block creation when satisfying `Tr`\n")])]),e._v("\ndiff --git a/src/descriptor/tr.rs b/src/descriptor/tr.rs\nindex 314c7f4..8487d56 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/descriptor/tr.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/descriptor/tr.rs")]),e._v("\n@@ -571,17 +571,14 @@ impl<Pk: MiniscriptKey> DescriptorTrait<Pk> for Tr<Pk> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                } else {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let ver = LeafVersion::default();\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let leaf_script = (ms.encode(), ver);\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let control_block_set = spend_info\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        .as_script_map()\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        .get(&leaf_script)\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                        .expect("Control block must exist in script map for every known leaf");\n')])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    // let control_block_set = spend_info\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    //     .as_script_map()\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    //     .get(&leaf_script)\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                    //     .expect("Control block must exist in script map for every known leaf");\n')]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                    let control_block = spend_info.control_block(&leaf_script).expect("Control block must exist in script map for every known leaf");\n')])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    wit.push(leaf_script.0.into_bytes()); // Push the leaf script\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                                                          // There can be multiple control blocks for a (script, ver) pair\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                                                          // Find the smallest one amongst those\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    let control_block = control_block_set\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        .iter()\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        .min_by(|x, y| x.as_inner().len().cmp(&y.as_inner().len()))\n")]),s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v('                        .expect("Atleast one control must exist for a known leaf");\n')])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    wit.push(control_block.serialize());\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    // Finally, save the minimum\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    min_wit = Some(wit);\n")])]),e._v("\n")])])]),s("p",[e._v("This is where things get more interesting: this section of code builds the witness to satisfy a Taproot descriptor. In case of a script-spend, we need to prove that the script we are using had been committed\ninto the public key of our "),s("code",[e._v("P2TR")]),e._v(' input. We do this by adding a "control block", that contains data about the parity of the key, the leaf version used, and the merkle path from the leaf we are using to spend\nup to the merkle root, which is committed into the public key. Once again, this is explained very well in '),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("BIP341")]),s("OutboundLink")],1),e._v(".")]),e._v(" "),s("p",[e._v("Before my patch the code was only getting the set of merkle paths that could lead from the root to the leaves that contain a given script. For context, the signature of "),s("code",[e._v("TaprootSpendInfo::as_script_map(&self)")]),e._v(" is:")]),e._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("/// Access the internal script map")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("pub")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("fn")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[e._v("as_script_map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("&")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("self")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("->")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("&")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("BTreeMap")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("Script")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("LeafVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("BTreeSet")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("TaprootMerkleBranch")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">>")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),s("p",[e._v('Then the code would look for the "shortest" path to that specific script, as it would save size in the final transaction (leaves that are more "deep" in the tree than others naturally have more hidden branches\nin their path to the root, and thus require a longer control block to reveal them all).')]),e._v(" "),s("p",[e._v("The issue here is that the "),s("code",[e._v("control_block")]),e._v(" variable is then serialized directly into the witness. But this is not a control block, it's just a set of merkle paths! A control block only has "),s("em",[e._v("one")]),e._v(" merkle path, and\nincludes the leaf version and the key parity bit.")]),e._v(" "),s("p",[e._v("Conveniently, the "),s("code",[e._v("TaprootSpendInfo")]),e._v(' struct also has this other method (I\'m including the implementation as well, because it shows that internally it does the same "trick" to find the shortest path):')]),e._v(" "),s("div",{staticClass:"language-rust extra-class"},[s("pre",{pre:!0,attrs:{class:"language-rust"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("/// Obtain a [`ControlBlock`] for particular script with the given version.")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("/// Returns [`None`] if the script is not contained in the [`TaprootSpendInfo`]")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("/// If there are multiple ControlBlocks possible, this returns the shortest one.")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("pub")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("fn")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token function-definition function"}},[e._v("control_block")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("&")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("self")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" script_ver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("&")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("Script")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("LeafVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("->")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("Option")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("<")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("ControlBlock")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v(">")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("let")]),e._v(" merkle_branch_set "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("self")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("script_map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("script_ver"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("?")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// Choose the smallest one amongst the multiple script maps")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("let")]),e._v(" smallest "),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" merkle_branch_set\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("iter")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("min_by")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token closure-params"}},[s("span",{pre:!0,attrs:{class:"token closure-punctuation punctuation"}},[e._v("|")]),e._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v(" y"),s("span",{pre:!0,attrs:{class:"token closure-punctuation punctuation"}},[e._v("|")])]),e._v(" x"),s("span",{pre:!0,attrs:{class:"token number"}},[e._v(".0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("cmp")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[e._v("&")]),e._v("y"),s("span",{pre:!0,attrs:{class:"token number"}},[e._v(".0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("len")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("expect")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[e._v('"Non-empty iterator"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("Some")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("ControlBlock")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n        internal_key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("self")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("internal_key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n        output_key_parity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("self")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("output_key_parity"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n        leaf_version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[e._v("LeafVersion")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("::")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("default")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n        merkle_branch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v(" smallest"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[e._v("clone")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(",")]),e._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),s("p",[e._v("So to fix this code we just have to use that method instead, and we can get it done in one single line!")]),e._v(" "),s("p",[e._v('Instead of removing the old code at the time I only commented it out, because I initially thought I would still have to look for the shortest script myself, and I figured the "sorting" code would come in handy\nlater on.')]),e._v(" "),s("p",[e._v("Also, if you are an acute observer, you might have noticed that there's a bug in this last snippet of code. Feel free to think about it a little bit, then check out the "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-bitcoin/pull/703",target:"_blank",rel:"noopener noreferrer"}},[e._v("PR"),s("OutboundLink")],1),e._v(" I made\nif you wanna know the answer!")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("git show 35378ad\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 35378ad01a6f2b8161a3f36448b24d031f8aeaec\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:27:14 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Consider key-spend max satisfaction weight\n")])]),e._v("\ndiff --git a/src/descriptor/tr.rs b/src/descriptor/tr.rs\nindex 8487d56..fabf860 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/descriptor/tr.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/descriptor/tr.rs")]),e._v("\n@@ -593,7 +593,7 @@ impl<Pk: MiniscriptKey> DescriptorTrait<Pk> for Tr<Pk> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn max_satisfaction_weight(&self) -> Result<usize, Error> {\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        let mut max_wieght = None;\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        let mut max_wieght = Some(65);\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        for (depth, ms) in self.iter_scripts() {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            let script_size = ms.script_size();\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            let max_sat_elems = match ms.max_satisfaction_witness_elements() {\n")])])])])]),s("p",[e._v("This is a little bug in the code that tries to compute what the maximum satisfaction weight would be for a descriptor. For instance, we use this in BDK to compute how many extra sats of fees we need to pay\nin order to target a given fee rate, assuming the descriptor is satisfied with the worst (larger and most expensive) path.")]),e._v(" "),s("p",[e._v("For Taproot descriptors, it's just a matter of iterating over the leaves in the tree and pick the most expensive one... or is it? This doesn't take into account that Taproot outputs can also be spent with\nkey-spend, which means just pushing a signature to the witness. This signature is 64 bytes long when using the new "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("SIGHASH_DEFAULT")]),s("OutboundLink")],1),e._v(" sighash, or 65 otherwise. Since we are thinking about the maximum satisfaction\nweight, or the worst case possible, we naturally pick the latter.")]),e._v(" "),s("p",[e._v("Note that theoretically you could build a Taproot address \"without\" an available key-path spend (by using an unspendable Schnorr public key), but the code here in rust-miniscript doesn't take that into\naccount, as there's no way that I'm aware of to specificy in a "),s("code",[e._v("tr()")]),e._v(" descriptor that the key is unspendable. So, while theoretically here we should first check whether the key-spend path is available before\naccounting for its weight, in practice this is always true in miniscript so we just use that as our starting worst case and update it later if necessary while iterating the tree leaves.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show b4878f8\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit b4878f816e9ede11d5ed947c06e03aa988e3e26f\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 14:27:53 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Look for taproot stuff in psbts\n")])]),e._v("\ndiff --git a/src/psbt/mod.rs b/src/psbt/mod.rs\nindex 9a8b17d..42c6ce8 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/psbt/mod.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/psbt/mod.rs")]),e._v("\n@@ -25,13 +25,14 @@ use bitcoin;\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use bitcoin::hashes::{hash160, ripemd160, sha256, sha256d};\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use bitcoin::secp256k1::{self, Secp256k1};\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use bitcoin::util::psbt::PartiallySignedTransaction as Psbt;\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use bitcoin::util::taproot::TapLeafHash;\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use bitcoin::Script;\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use interpreter;\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use miniscript::limits::SEQUENCE_LOCKTIME_DISABLE_FLAG;\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use miniscript::satisfy::{After, Older};\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use Satisfier;\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use {BitcoinECSig, Preimage32};\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use {BitcoinECSig, BitcoinSchnorrSig, Preimage32};\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("use {MiniscriptKey, ToPublicKey};\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("mod finalizer;\n")])]),e._v("@@ -231,6 +232,24 @@ impl<'psbt> PsbtInputSatisfier<'psbt> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("}\n")])]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("impl<'psbt, Pk: MiniscriptKey + ToPublicKey> Satisfier<Pk> for PsbtInputSatisfier<'psbt> {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn lookup_tap_key_spend_sig(&self) -> Option<BitcoinSchnorrSig> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        if let Some((sig, hash_ty)) = self.psbt.inputs[self.index].tap_key_sig {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Some(BitcoinSchnorrSig { sig, hash_ty })\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        } else {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            None\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn lookup_tap_leaf_script_sig(&self, pk: &Pk, lh: &TapLeafHash) -> Option<BitcoinSchnorrSig> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        let pk = pk.to_x_only_pubkey();\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        if let Some((sig, hash_ty)) = self.psbt.inputs[self.index].tap_script_sigs.get(&(pk, *lh)) {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Some(BitcoinSchnorrSig { sig: *sig, hash_ty: *hash_ty })\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        } else {\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            None\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")]),s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    fn lookup_ec_sig(&self, pk: &Pk) -> Option<BitcoinECSig> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        if let Some(rawsig) = self.psbt.inputs[self.index]\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            .partial_sigs\n")])])])])]),s("p",[e._v("This commit implements the Taproot-specific "),s("code",[e._v("Satisfier")]),e._v(" methods on "),s("code",[e._v("PsbtInputSatisfier")]),e._v(". The code to produce a valid witness (i.e. "),s("em",[e._v("satisfy")]),e._v(") a descriptor by looking for Taproot key-spend or script-spend signatures\nis already implemented, so it's just a matter of actually returning those, if they are present in a PSBT.")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 80da0ba\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 80da0ba9b742b2dee23e7302e2f95a6e96b1d6ed\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 16:54:27 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Iter keys in `MultiA`\n")])]),e._v("\ndiff --git a/src/miniscript/iter.rs b/src/miniscript/iter.rs\nindex 36c4b69..a54a371 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/miniscript/iter.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/miniscript/iter.rs")]),e._v("\n@@ -121,7 +121,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn get_leaf_pk(&self) -> Vec<Pk> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match self.node {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::PkK(ref key) => vec![key.clone()],\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) => keys.clone(),\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) | Terminal::MultiA(_, ref keys) => keys.clone(),\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => vec![],\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("@@ -139,7 +139,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match self.node {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::PkH(ref hash) => vec![hash.clone()],\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::PkK(ref key) => vec![key.to_pubkeyhash()],\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) => keys.iter().map(Pk::to_pubkeyhash).collect(),\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) | Terminal::MultiA(_, ref keys) => keys.iter().map(Pk::to_pubkeyhash).collect(),\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => vec![],\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("@@ -155,7 +155,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match self.node {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::PkH(ref hash) => vec![PkPkh::HashedPubkey(hash.clone())],\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::PkK(ref key) => vec![PkPkh::PlainPubkey(key.clone())],\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) => keys\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            Terminal::Multi(_, ref keys) | Terminal::MultiA(_, ref keys) => keys\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                .into_iter()\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                .map(|key| PkPkh::PlainPubkey(key.clone()))\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                .collect(),\n")])]),e._v("@@ -170,7 +170,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    pub fn get_nth_pk(&self, n: usize) -> Option<Pk> {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match (&self.node, n) {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::PkK(ref key), 0) => Some(key.clone()),\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) => keys.get(n).cloned(),\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) | (&Terminal::MultiA(_, ref keys), _) => keys.get(n).cloned(),\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => None,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("@@ -186,7 +186,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match (&self.node, n) {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::PkH(ref hash), 0) => Some(hash.clone()),\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::PkK(ref key), 0) => Some(key.to_pubkeyhash()),\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) => keys.get(n).map(Pk::to_pubkeyhash),\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) | (&Terminal::MultiA(_, ref keys), _) => keys.get(n).map(Pk::to_pubkeyhash),\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => None,\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("    }\n")])]),e._v("@@ -199,7 +199,7 @@ impl<Pk: MiniscriptKey, Ctx: ScriptContext> Miniscript<Pk, Ctx> {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("        match (&self.node, n) {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::PkH(ref hash), 0) => Some(PkPkh::HashedPubkey(hash.clone())),\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::PkK(ref key), 0) => Some(PkPkh::PlainPubkey(key.clone())),\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) => {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            (&Terminal::Multi(_, ref keys), _) | (&Terminal::MultiA(_, ref keys), _) => {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                keys.get(n).map(|key| PkPkh::PlainPubkey(key.clone()))\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            }\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("            _ => None,\n")])])])])]),s("p",[e._v("Taproot descriptors add a new miniscript operator called "),s("code",[e._v("multi_a()")]),e._v(" which behaves like "),s("code",[e._v("multi()")]),e._v(" in non-Taproot descriptors, but uses the new "),s("a",{attrs:{href:"https://github.com/bitcoin/bips/blob/master/bip-0342.mediawiki#script-execution",target:"_blank",rel:"noopener noreferrer"}},[s("code",[e._v("OP_CHECKSIGADD")]),s("OutboundLink")],1),e._v(" opcode when serialized in a script.")]),e._v(" "),s("p",[e._v("When this was added, somebody forgot to update the various methods that iterate over the public keys of a descriptor to correctly return the keys contained in "),s("code",[e._v("multi_a()")]),e._v(" - essentially, it was falling back in\nthe default case used by the operators that don't contain any key, but this one does!")]),e._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("$ git show 8b108c5\n")])])]),s("div",{staticClass:"language-diff extra-class"},[s("pre",{pre:!0,attrs:{class:"language-diff"}},[s("code",[e._v("commit 8b108c5c0bf50b66b7220746525742b71f6cd4b4\nAuthor: Alekos Filini <alekos.filini@gmail.com>\nDate:   Sat Nov 13 17:26:53 2021 +0100\n\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("   Fix witness generation for `MultiA`\n")])]),e._v("\ndiff --git a/src/miniscript/satisfy.rs b/src/miniscript/satisfy.rs\nindex 655436e..ab43707 100644\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("--- a/src/miniscript/satisfy.rs")]),e._v("\n"),s("span",{pre:!0,attrs:{class:"token coord"}},[e._v("+++ b/src/miniscript/satisfy.rs")]),e._v("\n@@ -1264,7 +1264,7 @@ impl Satisfaction {\n"),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                // Collect all available signatures\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                let mut sig_count = 0;\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                let mut sigs = vec![vec![vec![]]; keys.len()];\n")])]),s("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[s("span",{pre:!0,attrs:{class:"token prefix deleted"}},[e._v("-")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                for (i, pk) in keys.iter().enumerate() {\n")])]),s("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[s("span",{pre:!0,attrs:{class:"token prefix inserted"}},[e._v("+")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                for (i, pk) in keys.iter().rev().enumerate() {\n")])]),s("span",{pre:!0,attrs:{class:"token unchanged"}},[s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                    match Witness::signature::<_, _, Ctx>(stfr, pk, leaf_hash) {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                        Witness::Stack(sig) => {\n")]),s("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[e._v(" ")]),s("span",{pre:!0,attrs:{class:"token line"}},[e._v("                            sigs[i] = sig;\n")])])])])]),s("p",[e._v("And finally, the last little fix: the "),s("code",[e._v("multi_a()")]),e._v(" operator is satisfied by pushing to the witness either a signature (if you have one available for that specific public key) or an empty vector. The problem is,\nthey have to be in the right order to match the order of public keys in your Taproot script.")]),e._v(" "),s("p",[e._v("rust-miniscript was pushing them in reverse order, so script validation was always failing for multisigs that had more than 1 key. Adding a "),s("code",[e._v(".rev()")]),e._v(" to the iterator fixed the issue.")]),e._v(" "),s("h2",{attrs:{id:"conclusion"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[e._v("#")]),e._v(" Conclusion")]),e._v(" "),s("p",[e._v("And that was it! We now have a fully working "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-bitcoin",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-bitcoin"),s("OutboundLink")],1),e._v(" and "),s("a",{attrs:{href:"https://github.com/rust-bitcoin/rust-miniscript",target:"_blank",rel:"noopener noreferrer"}},[e._v("rust-miniscript"),s("OutboundLink")],1),e._v(" ready for Taproot.")]),e._v(" "),s("p",[e._v("In "),s("a",{attrs:{href:"/blog/2021/12/first-bdk-taproot-tx-look-at-the-code-part-2"}},[e._v("Part 2")]),e._v(" I will go over the code changes in BDK, but I think it's now time for you and I to take a break ")])])}),[],!1,null,null,null);t.default=a.exports}}]);